\section{$\SampBQP$ Delegation Protocol for Fully Classical Client}
\label{sec:qpip0_all}

In this section, we create a delegation protocol for $\SampBQP$ with fully classical clients following the approach taken in \cite{FOCS:Mahadev18a}.
The core protocol, $\PiMeasure$, allows a $\BQP$ prover to ``commit a state" for a classical verifier to choose a measurement basis and obtain corresponding measurement results.
Composing it with the $\QPIP_1$ protocol for $\BQP$ from \cite{mf16} results in a $\QPIP_0$ protocol for $\BQP$.
We now try to compose $\PiMeasure$ similarly with our $\QPIP_1$ protocol $\PiSamp$ for $\SampBQP$ in order to obtain a $\QPIP_0$ protocol for $\SampBQP$ 

A direct composition between $\PiSamp$ and $\PiMeasure$, however, results in $\PiNaive$ which does not provide reasonable completeness or accuracy guarantees.
As we will see, this is due to $\PiMeasure$ itself having peculiar and weak guarantees:
the client doesn't always obtain measurement outcomes even if the server were honest.
When that happens under the $\BQP$ context, the verifier can simply accept the prover at the cost of some soundness error;
under our $\SampBQP$ context, however, we must run many copies of $\PiNaive$ in parallel so the verifier can generate its outputs from some copy.
We spend the majority of this section analyzing the soundness of this parallel repetition.

\subsection{Mahadev's measurement protocol}\label{sec:urmila4}

$\PiMeasure$ is a 4-round protocol between a verifier (which corresponds to our client) and a prover (which corresponds to our server).
The verifier chooses a string $h$ specifying the measurements he wants to make, and generates keys $pk, sk$ from $h$. It sends $pk$ to the prover. The prover ``commits" to a state $\rho$ of its choice using $pk$ and replies with its commitment $y$.
The verifier must then choose between two options: do a \emph{testing round} or a \emph{Hadamard round}.
In a testing round the verifier can catch cheating provers,
and in a Hadamard round the verifier receives some measurement outcome.
He sends his choice to the prover, and prover replies accordingly. If the verifier chose testing round, he checks the prover's reply against the previous commitment, and rejects if he sees an inconsistency. If the verifier chose Hadamard round, he calculates $M_{XZ}(\rho, h)$ based on the reply.
We now formally describe the interface of $\PiMeasure$ while omitting the implementation details.

\begin{protocol}{Mahadev's measurement protocol $\PiMeasure=(\PMeasure, \VMeasure)$}
	\label{proto:urmila4}

	Inputs:
	\begin{itemize}
		\item Common input: Security parameter $1^\lambda$ where $\lambda\in\bbN$.
		\item Prover's input: a state $\rho\in\cB^{\otimes n}$ for the verifier to measure.
		\item Verifier's input: the measurement basis choice $h \in \zo^n$
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:measure1} The verifier generates a public and secret key pair $(pk, sk)\leftarrow\cVMeasure{1}(1^\lambda, h)$. It sends $pk$ to the prover.
		\item \label{step:measure2} The prover generates $(y, \sigma)\leftarrow\cPMeasure{2}(pk, \rho)$.
			$y$ is a classical ``commitment", and $\sigma$ is some internal state.
			He sends $y$ to the verifier.
		\item \label{step:measure3} The verifier samples $c\xleftarrow{\$}\zo$ uniformly at random and sends it to the prover. $c=0$ indicates a \emph{testing round}, while $c=1$ indicates a \emph{Hadamard round}.
		\item \label{step:measure4} The prover generates a classical string $a\leftarrow\cPMeasure{4}(pk, c, \sigma)$ and sends it back to the verifier.
		\item \label{step:output} If it is a testing round ($c=0$), then the verifier generates and outputs $o\leftarrow\cVMeasure{T}(pk, y, a)$ where $o\in\set{\Acc, \Rej}$.
			If it is a Hadamard round ($c=1$), then the verifier generates and outputs $v\leftarrow\cVMeasure{H}(sk, h, y, a)$.
	\end{enumerate}
\end{protocol}

$\PiMeasure$ has negligible completeness errors.
It gives the following \emph{binding property} against cheating provers:
if a prover would always succeed on the testing round, then there exists some $\rho$ so that for any $h$ the verifier obtains $M_{XZ}(\rho, h)$ if he had chosen Hadamard round.

\begin{lemma}[binding property of $\PiMeasure$; special case of Claim 7.1 in \cite{FOCS:Mahadev18a}]
	\label{lem:urmila-binding}
	Let $\PMeasureStar$ be a $\BQP$ cheating prover for $\PiMeasure$ and $\lambda$ be the security parameter. Under the QLWE assumption, if $\PMeasureStar$ passes the testing round with probability $1-\negl(\lambda)$ for all $h$, then there exists some $\rho$ so that for all verifier's input $h \in \zo^n$, the verifier's outputs on the Hadamard round is computationally indistinguishable from $M_{XZ}(\rho, h)$.
\end{lemma}

We now use $\PiMeasure$ to transform our $\QPIP_1$ Protocol for $\SampBQP$, $\PiSamp=(\PSamp, \VSamp)$, to a corresponding $\QPIP_0$ protocol $\PiNaive$.
Recall that in $\PiSamp$ the verifier takes $X$ and $Z$ measurements on the prover's message.
In $\PiNaive$ we let the verifier use $\PiMeasure$ to learn those measurement outcomes instead.

\begin{protocol}{Intermediate $\QPIP_0$ protocol $\PiNaive$ for a $\SampBQP$ problem $(D_x)_{x\in\set{0, 1}^*}$}
	\label{proto:qpip0_naive}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ where $\lambda\in\bbN$
		\item Error parameter $\eps\in(0, 1)$
		\item Classical input $x\in\zo^n$ to the $\SampBQP$ instance
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:naive1} The verifier chooses a $XZ$-measurement $h$ from the distribution specified in \stepref{qpip1-verify} of $\PiSamp$.
		\item \label{step:naive2} The prover prepares $\rho$ by running \stepref{qpip1-state-gen} of $\PiSamp$.
		\item \label{step:urmila-in-naive}
			The verifier and prover run $(\PMeasure(\rho), \VMeasure(h))(1^\lambda)$.
			\begin{enumerate}
				\item The verifier samples $(pk, sk)\leftarrow\cVNaive{1}(1^\lambda, h)$ and sends $pk$ to the prover.
				\item The prover runs $(y, \sigma)\leftarrow\cPNaive{2}(pk, \rho)$ and sends $y$ to the verifier.
					Here we allow the prover to abort by sending $y=\bot$, which does not benefit cheating provers but is useful for analysis.
				\item\label{step:c-urmila-in-naive} The verifier samples $c\xleftarrow{\$}\zo$ and sends it to the prover.
				\item The prover replies $a\leftarrow\cPNaive{4}(pk, c, \sigma)$.
				\item
					If it is a testing round, the verifier accepts or rejects based on the outcome of $\PiMeasure$.
					If it is a Hadamard round, the verifier obtains $v$.
			\end{enumerate}
		\item \label{step:naive-output} If it's a Hadamard round, the verifier finishes the verification step of Protocol~\ref{ProtoQPIP1} by generating and outputting $(d, z)$
	\end{enumerate}
\end{protocol}

There are several problems with using $\PiNaive$ as a $\SampBQP$ protocol. First, since the verifier doesn't get a sample if he had chosen the testing round in Step~\ref{step:c-urmila-in-naive}, the protocol has completeness error at least $1/2$. Moreover, since $\PiMeasure$ does not check anything on the Hadamard round, a cheating prover can give up passing the testing round and breaks the commitment on the Hadamard round, with only a constant $1/2$ probability of being caught.
However, we can show that $\PiNaive$ has a binding property similar to $\PiMeasure$:
if a cheating prover $\PNaiveStar$ passes the testing round with overwhelming probability whenever it doesn't abort on the second message,
then the corresponding output $(d, z)\leftarrow(\PNaiveStar, \VNaive)$ is close to $(d, z_{ideal})$.
Recall the ideal output
$$\begin{cases}
	z_{ideal}=\bot & \text{if } d=\Rej\\
	z_{ideal}\leftarrow D_x & \text{if } d=\Acc
\end{cases}$$
is drawn from the true distribution instead when $\PNaiveStar$ is accepted.
The intuition of the proof is to reduce to \Cref{lem:urmila-binding} by constructing another $\BQP$ prover $\Pstar$ for $\PiMeasure$.
Specifically, $\Pstar$ uses $\PNaiveStar$'s strategy when it doesn't abort, otherwise honestly chooses some default state for the verifier to measure.
We now state the theorem and proof.

\begin{theorem}[binding property of $\PiNaive$]
	\label{lem:naive-qpip0-binding}
	Let $\PNaiveStar$ be a cheating $\BQP$ prover for $\PiNaive$ and $\lambda$ be the security parameter.
	Suppose that $\Prob{d=\Acc\mid y\ne\bot, c=0}$ is overwhelming, \Ethan{This good?}
	under the QLWE assumption, then the verifier's output in the Hadamard round is $O(\eps)$-computationally indistinguishable from $(d, z_{ideal})$.
\end{theorem}
\begin{proof}
	We first introduce the \emph{dummy strategy} where the prover chooses $\rho$ as the maximally mixed state and executes the rest of the protocol honestly.
	It is straightforward to verify that this prover would be accepted in the testing round with probability $1-\negl(\lambda)$,
	but has negligible probability passing the verification after the Hadamard round.

	Now we construct another cheating $\BQP$ prover $\Pstar$ that is non-aborting and almost perfect as follows.
	For the second message, run $(y, \sigma)\leftarrow\cPNaiveStar{2}(pk, \rho)$.
	If $y\ne\bot$, then reply $y$;
	else, run the corresponding step of the dummy strategy and reply with its results.
	For the fourth message, if $y\ne\bot$, run and reply with $a\leftarrow\cPNaiveStar{4}(pk, c, \sigma)$;
	else, continue the dummy strategy.

	Observe that this $\Pstar$ passes testing round with overwhelming probability by construction,
	so we can apply \Cref{lem:urmila-binding} to the $\PiMeasure$ call to use its binding property (\Cref{lem:urmila-binding}).
	That is, there exists some $\rho$ such that $v=M_{XZ}(\rho, h)$.
	Combining it with $\PiSamp$'s soundness (\Cref{QPIP1thm}),
	we see that $(d', z')\leftarrow(\Pstar, \VNaive)(1^\lambda, 1^{1/\varepsilon}, x)$ is $\eps$-computationally indistinguishable to $(d', z_{ideal}')$.

	Now we relate $(d', z')$ back to $(d, z)$.
	First, conditioned on that $\PNaiveStar$ aborts, since dummy strategy will be rejected with overwhelming probability in Hadamard round,
	we have $(d', z')$ is $O(\varepsilon)$-computationally indistinguishable to $(\Rej, \bot)=(d, z)$.
	On the other hand, conditioned on $\PNaiveStar$ not aborting, clearly $(d, z)=(d', z')$.
	So $(d, z)$ is $O(\eps)$-computationally indistinguishable to $(d', z')$,
	which in turn is $\negl(\lambda)$-computationally indistinguishable to $(d', z_{ideal}')$.
	So $\abs{d-d'}\leq O(\eps)$,
	and $(d, z_{ideal})$ is $O(\eps)$-computationally indistinguishable to $(d', z_{ideal}')$.
	Combining everything, we conclude that $(d, z)$ is $O(\eps)$-computationally indistinguishable to $(d, z_{ideal})$.
\end{proof}

\subsection{$\QPIP_0$ protocol for $\SampBQP$} \label{sec:qpip0}

We now introduce our $\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$.
It is essentially a $m$-fold parallel repetition of $\PiNaive$,
but instead of having each copy running testing round or Hadamard round uniformly at random, we randomly pick one copy to run Hadamard round to get our samples and run testing round on all other $m-1$ copies.
Intuitively, if the server wants to cheat by sending something not binding on some copy,
he will be caught when that copy is a testing round, which is with probability $1-1/m$.
This over-simplified analysis does not take into account that the server might create entanglements between the copies, however, so the correct analysis is more technically involved.

In the description of our protocol below, we describe $\PiNaive$ and $\PiMeasure$ in details in order to introduce notations that we need in our analysis.

\begin{protocol}{$\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$}
	\label{proto:QPIP0samp}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ for $\lambda\in\bbN$.
		\item Accuracy parameter $1^{1/\eps}$ for the $\SampBQP$ instance
		\item Input $x\in\zo^{\poly(\lambda)}$ for the $\SampBQP$ instance
	\end{itemize}

	Ingredient: Let $m=O(1/\eps^2)$ be the number of parallel repetitions to run.

	Protocol:
	\begin{enumerate}
		\item The verifier generates $m$ independently copies of basis choices $\vec{h}=(h_1,\ldots,h_m)$ as in \stepref{naive1} of $\PiNaive$.
		\item The prover prepares $\rho^{\otimes m}$; each copy of $\rho$ is prepared as in \stepref{naive2} of $\PiNaive$.
		\item The verifier generates $m$ key pairs for $\PiMeasure$, $\vec{pk}=(pk_1,\ldots,pk_m)$ and $\vec{sk}=(sk_1,\ldots,sk_m)$, as in \stepref{measure1} of $\PiMeasure$.
			It sends $\vec{pk}$ to the prover.
		\item The prover generates $\vec{y}=(y_1,\ldots,y_m)$ and $\sigma$ as in \stepref{measure2} of $\PiMeasure$.
			It sends $\vec{y}$ to the verifier.
		\item The verifier samples $r\xleftarrow{\$}[m]$ which is the copy to run Hadamard round for.
			For $1\leq i\leq m$, if $i\ne r$ then set $c_i\leftarrow 0$, else set $c_i\leftarrow 1$.
			It sends $\vec{c}=(c_1,\ldots,c_m)$ to the prover.
		\item The prover generates $\vec{a}$ as in \stepref{measure4} of $\PiMeasure$, and sends it back to the verifier.
		\item The verifier computes the outcome for each round as in \stepref{naive-output} of $\PiNaive$.
			If any of the testing round copies are rejected, the verifier outputs $(\Rej, \bot)$.
			Else, it outputs the result from the Hadamard round copy.
	\end{enumerate}
\end{protocol}
By inspection, $\PiSampZ$ is a $\QPIP_0$ protocol for $\SampBQP$ with negligible completeness error.
To show that it is computationally sound, we first use the partition lemma from \cite{arXiv:ChiaChungYam19}.
\Ethan{Tried to ``slow down" on this paragraph}
It says that for each copy $i\in[m]$, there exist two efficient ``projectors" \footnote{Actually they are not projectors, but for the simplicity of this discussion let's assume they are.} $G_{0,i}$ and $G_{1,i}$ in the prover's internal space with $G_{0,i}+G_{1,i} \approx Id$.
$G_{0,i}$ intuitively represents the subspace where the server does not knows the answer to the testing round on the $i$-th copy, while $G_{1,i}$ represents the subspace where the server does.
By using this partition lemma iteratively, we can decompose the prover's internal state $\ket{\psi}$.
First we apply it to the first copy, writing $\ket{\psi}=G_{0,1}\ket{\psi}+G_{1,1}\ket{\psi}=\ket{\psi_0}+\ket{\psi_1}$.
The component $\ket{\psi_0}$ would then get rejected as long as the first copy is a testing round,
which occurs with high probability.
More precisely, the output corresponding to $\ket{\psi_0}$ is $1/m$-close to the ideal distribution that just rejects all the time.
On the other hand, $\ket{\psi_1}$ is now binding on the first copy;
we now similarly apply the partition lemma to the second copy of $\ket{\psi_1}$.
We write $\ket{\psi_1}=G_{0,2}\ket{\psi_1}+G_{1,2}\ket{\psi_1}=\ket{\psi_{10}}+\ket{\psi_{11}}$, and apply the same argument about $\ket{\psi_{10}}$ and $\ket{\psi_{11}}$.
We then continue to decompose $\ket{\psi_{11}}=\ket{\psi_{110}}+\ket{\psi_{111}}$ and so on, until we reach the last copy and obtain $\ket{\psi_{1^m}}$.
This $\ket{\psi_{1^m}}$ term represents the ``good" component where the prover knows the answer to every testing round and therefore has high accept probability.
Intuitively, $\ket{\psi_{1^m}}$ also satisfies some binding property,
so the verifier should obtain a measurement result of some state on the Hadamard round copy,
and the analysis from the $\QPIP_1$ protocol $\PiSamp$ follows.

There is an additional issue, however, as $G_{1,i}$ don't commute with $G_{1,j}$, so $\ket{\psi_{1^m}}$ is unfortunately only binding for the $m$-th copy.
To solve this problem, we start with a pointwise argument and fix the Hadamard round on the $i$-th copy where $\ket{\psi_{1^i}}$ is binding,
and show that the corresponding output is $O(\norm{\ket{\psi_{1^{i-1}0}}})$-close to ideal.
We can later average out this error over the different choices of $i$, since not all $\norm{\ket{\psi_{1^{i-1}0}}}$ can be large at the same time.

Also as a careful reader might have noticed, in fact the prover's space don't always decompose cleanly. In \cite{arXiv:ChiaChungYam19} this is solved by splitting the space into parts that are accepted with probability higher or lower than a small threshold $\gamma$. However, states with accept probability really close to the threshold $\gamma$ can not be classified, so they need to average over randomly chosen $\gamma$ to have $G_{0,i}+G_{1,i} \approx Id$.
Now we give a formal description of the partition lemma.

\begin{lemma}[partition lemma; revision of Lemma 3.5 of \cite{arXiv:ChiaChungYam19}\footnote{$G_{0}$ and $G_{1}$ of this version are created from doing $G$ of \cite{arXiv:ChiaChungYam19} and post-select on the $ph,th,in$ register being $0^t01$ or $0^t11$ then discard $ph,th,in$. Property~\ref{property:partition-err} corresponds to Property~1. Property~\ref{property:partition-testing} corresponds to Property~4, with $2^{m-1}$ changes to $m-1$ because we only have $m$ possible choices of $\{c\}$. Property~\ref{property:partition-binding} corresponds to Property~5. Property~\ref{property-partition-norm-sum} comes from the fact that $G_0$ and $G_1$ are post-selections of orthogonal results of the same $G$.}]\label{lem:partition2}
	Let $\lambda$ be the security parameter, and $\gamma_0 \in[0,1]$ and $T\in \mathbb{N}$ be parameters that will relate to the randomly-chosen threshold $\gamma$.
	Let $(U_0,U)$ be a prover's strategy in a $m$-fold parallel repetition of $\PiMeasure$, where $U_0$ is how the prover generates $\vec{y}$ on the second message, and $U$ is how the prover generates $\vec{a}$ on the fourth message. Denote the string $0^{i-1}10^{m-i} \in \zo^m $ as $e_i$, which corresponds to Hadamard round on the $i$-th copy and testing round on all others.

	For all $i\in[m]$, $\gamma \in \L\{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}\R\}$, there exist two efficient quantum circuit $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ such that for all (possibly sub-normalized) $\poly(\lambda)$-qubits quantum state $\ket{\psi}_{\regX,\regZ}$,  

	\begin{align}
		G_{0,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{0,i,\gamma}}_{\regX,\regZ} \\ G_{1,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}  \\
		\ket{\psi}_{\regX,\regZ} =&   \ket{\psi_{0,i,\gamma}}_{\regX,\regZ}+ \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}+\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}
	\end{align}

	Note that $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ has failure probabilities, and this is reflected by the fact that $\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}$ and $\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}$ are  sub-normalized. $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ depend on $(U_0,U)$ and $\vec{pk},\vec{y}$.

	Furthermore, the following properties are satisfied for all $i\in[m]$.
	\begin{enumerate}
		\item \label{property:partition-err}  $$\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\|^2 \leq \frac{6}{T}+\negl(\lambda),$$

			where the averaged is over uniformly sampled $\gamma$. This also implies
			\begin{align}
				\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\| \leq \sqrt{\frac{6}{T}}+\negl(\lambda)
			\end{align}
			by Cauchy's inequality.

		\item \label{property:partition-testing}
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and  $j\neq i$, we have
			\begin{align}
				\norm{ P_{acc, i} \circ U\frac{\ket{e_j}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}}^2 \leq (m-1)\gamma_0+\negl(\lambda),
			\end{align}
			where $P_{acc, i}$ are projector to the states that $i$-th testing round accepts with $pk_i,y_i$, including the last measurement the prover did before sending $\vec{a}$.  This means that $\ket{\psi_{0,i,\gamma}}$ is rejected by the $i$-th testing round with high probability.
		\item \label{property:partition-binding}
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and $j\neq i$, there exists an efficient quantum algorithm $\ext_i$ such that
			\begin{align}
				\norm{P_{acc, i} \circ \ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)}^2 =1-\negl(\lambda).
			\end{align}

			% \begin{align*}  
			%   \Pr\left[M_{\regX_i}\circ \ext_i\left(\frac{\ket{\{c\}}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)\in \Acc_{pk_i,y_i}\right]=1-\negl(\secpar).
			%   \end{align*}
			This will imply that $\ket{\psi_{1,i,\gamma}}$ is binding to the $i$-th Hadamard round.

		\item \label{property-partition-norm-sum}
			For all $\gamma$,
			\begin{align}
				\norm{\ket{\psi_{0,i,\gamma}}}^2+ \norm{\ket{\psi_{1,i,\gamma}}}^2 \leq  \norm{\ket{\psi}}^2
			\end{align}
	\end{enumerate}
\end{lemma}

By Property~\ref{property:partition-testing} of the partition lemma above,
it clearly also follows that \Ethan{This ok?}
\begin{rmk}
	\label{lem:partition-testing}
	For all $\gamma\in\set{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}}$, and all $i,j\in[m]$ such that $j<i-1$, we have
	$$\norm{P_{acc,i,z} U \ket{e_i, \psi_{1^j0,\gamma}}}^2\leq (m-1)\gamma_0+\negl(n).$$
\end{rmk}

We now decompose the prover's internal state by using \Cref{lem:partition2} iteratively.
Let $\ket{\psi}$ be the state the prover holds before he receives $\vec{c}$;
we denote the corresponding Hilbert space as $H_{\regX,\regZ}$.
For all $k\leq m$, $d\in \zo^k$, $\gamma=(\gamma_1, \ldots, \gamma_k)$ where each $\gamma_j\in\set{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}}$ \Ethan{This ok?}, and $\ket{\psi} \in H_{\regX,\regZ}$, define $$\ket{\psi_{d,\gamma}}\defeq G_{d_k,k,\gamma_k}\ldots G_{d_2,2,\gamma_2} G_{d_1,1,\gamma_1} \ket{\psi}.$$
For all $i\in[m]$, we then decompose
\begin{equation}
	\label{eq:partition-string}
	\ket{\psi}=\sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
\end{equation}
where $\ket{\psi_{err,i,\gamma}}$ denotes the error state from decomposing $\ket{\psi_{1^{i-1},\gamma}}$.

We denote the projector in $H_{\regX,\regZ}$ corresponding to outputting string $z$ when doing Hadamard on $i$-th copy as $P_{acc,i,z}$.
Note that $P_{acc,i,z}$ also depends on $\vec{pk}, \vec{y}$, and $(sk_i, h_i)$ since it includes the measurement the prover did before sending $\vec{a}$,  verifier's checking on $(m-1)$ copies of testing rounds, and  the verifier's final computation from $(sk_i,h_i,y_i,a_i)$.

We denote the string $0^{i-1}10^{m-i} \in \zo^m$ as $e_i$. The output string corresponding to $\ket{\psi} \in H_{\regX,\regZ}$ when $c=e_i$ is then
\begin{equation}
	\label{eq:zi-def}
	z_i\defeq \E_{pk,y} \sum_z \norm{P_{acc,i,z} U\ket{e_i,\psi}}^2\proj{z},
\end{equation}
where $\ket{e_i,\psi}=\ket{e_i}_\regC\ket{\psi}_{\regX,\regZ}$ and $U$ is the unitary the prover applies on the last round.
Note that we have averaged over $\vec{pk}, \vec{y}$ where as previously everything has fixed $\vec{pk}$ and $\vec{y}$.
Now we define
\begin{equation}
	\label{eq:zgoodi-def}
	z_{good, i}=\E_{\gamma, pk, y} \sum_z \norm{P_{acc,i,z} U\ket{e_i,\psi_{1^{i-1}1,\gamma}}}^2\proj{z}
\end{equation}
as the output corresponding to the component that would pass all $i$ testing rounds.
We will show that it is $O(\norm{\ket{\psi_{1^{i-1}0}}})$-close to $z_i$.
Before doing so, we present a technical lemma.
\begin{lemma}\label{lem:samp-tech}
	For any state $\ket{\psi}$,  $\ket{\phi}$ and projectors $\{P_z\}$ such that $\sum_z P_z \leq Id$ and $P_z P_{z'} =0 $ for all $z\neq z'$, we have
	$$  \sum_z |\vev{\psi|P_z|\phi}| \leq \norm{\psi}\norm{\phi} $$
\end{lemma}
\begin{proof}
	\begin{align}
		\sum_z |\vev{\psi|P_z|\phi}| =&\sum_z|\vev{\psi|P_zP_z|\phi}| \nn \\
		\leq& \sum_z \norm{\bra{\psi}P_z} \norm{ P_z\ket{\phi}} \nn \\
		\leq&  \sqrt{\sum_z \norm{P_z\ket{\psi}}^2} \sqrt{\sum_z\norm{P_z\ket{\phi}}^2} \nn \\
		\leq& \sqrt{\norm{\sum_z P_z\ket{\psi}}^2 } \sqrt{\norm{\sum_z P_z\ket{\phi}}^2 } \nn \\
		\leq & \norm{\ket{\psi}}\norm{\ket{\phi}},
	\end{align}
	where we used Cauchy's inequality on the second and third line and $P_z P_{z'} =0 $ on the fourth line.
\end{proof}

Now we can estimate $z_i$ using $z_{good, i}$, with errors on the orders of $\norm{\ket{\psi_{1^{i-1}0}}}$.
This error might not be small in general,
but we can average it out later by considering uniformly random $i\in[m]$.
The analysis is tedious but straightforward;
we simply expand $z_i$ and bound the terms other than $z_{good, i}$.

\begin{lemma}
	\label{thm:zi-zgoodi}
	$$\tr\abs{z_i-z_{good, i}}\leq\E_{pk, y, \gamma}\L[\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}\R]+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)$$
\end{lemma}
\begin{proof}
	We take expectation of \Cref{eq:partition-string} over $\gamma$
	$$\ket{\psi}=\E_{\gamma}\left[
		\sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
	\right]$$
	and expand $z_i$ from \Cref{eq:zi-def} as
	\begin{align}
		z_i=& z_{good,i}+ \E_{pk, y, \gamma} \sum_z \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U   \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}+
		\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}  \R. \nn \\
		+&  \sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&  \bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U  \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&\L.   \sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} +\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}} \R] \proj{z} , \nn     
		%=& z_{good,i} +(\text{terms with } \psi_{1^j0},\, j\neq i ) + (\text{terms with } \psi_{1^{i-1}0}) +(\text{terms with }err )
	\end{align}
	where we omitted writing out $e_i$.
	Therefore we have
	\begin{align*}
		\tr|z_i-z_{good,i}|\leq& \E_{pk, y, \gamma} \sum_z \L[ \sum_{k=0}^{i-1} \sum_{j=0}^{i-1} \L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^j0,\gamma}} \R|+
		2 \sum_{k=0}^{i-1} \L|\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} \R|  \R. \\
		+& 2 \sum_{k=0}^{i-1}\sum_{j=1}^{i}\L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\ket{\psi_{err,j,\gamma}}\R|    
		+2 \sum_{j=1}^{i}\L|\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \\
		+&\L. \sum_{k=1}^{i}\sum_{j=1}^{i}\L| \bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \R] \\ %%%%%%%%%
	\end{align*}
	by the triangle inequality.
	The last three error terms sum to $O\L(\frac{m^2}{\sqrt{T}}\R)$ by \Cref{lem:samp-tech} and \Cref{property:partition-err} of \Cref{lem:partition2}.
	As for the first two terms, by \Cref{lem:samp-tech} and \Cref{lem:partition-testing}, we see that
	\begin{align*}
		\sum_z \sum_{k=0}^{i-1}\sum_{j=0}^{i-1}
		&\abs{\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^j0,\gamma}}} \\
		&\leq\sum_z \abs{\bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^{i-1}0,\gamma}}} + O\L(m^2(m-1)\gamma_0\R) \\
		&\leq\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2 + O\L(m^2(m-1)\gamma_0\R)
	\end{align*}
	and similarly
	\begin{align*}
		\sum_z\sum_{k=0}^{i-1}
		&\abs{\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}}\\
		&\leq\sum_z\abs{\bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}}+O\L(m\sqrt{(m-1)\gamma_0}\R)\\
		&\leq\norm{\ket{\psi_{1^i,\gamma}}}+O\L(m\sqrt{(m-1)\gamma_0}\R)
	\end{align*}
\end{proof}

Now let $z_{true}$, as a mixed state, be correctly sampled from the $\SampBQP$ instance $D_x$,
and let $z_{ideal, i}=\tr(z_{good, i})z_{true}$.
We show that $z_{ideal, i}$ is close to $z_{good, i}$.
\begin{lemma}
	\label{thm:zgood-zideal}
	$z_{good, i}$ is $O(\eps)$-computationally indistinguishable to $z_{ideal, i}$,
	where $\eps\in\bbR$ is the accuracy parameter picked earlier in $\PiSampZ$.
\end{lemma}
\begin{proof}
	For every $i\in [m]$ and every prover strategy $(U_0,U)$ for $\PiSampZ$, consider the following composite strategy of the prover for $\PiNaive$. Note that the prover only interact with the verifier in Step~\ref{step:urmila-in-naive} of $\PiNaive$ where $\PiMeasure$ is run, so we describe the prover's action in terms of the four rounds of communication in $\PiMeasure$.

	The prover tries to run $U_0$ by taking the verifier's input as $i$-th copy of $\PiMeasure$ in $\PiSampZ$ and simulating other $m-1$ copies by himself. The prover then picks a uniformly random $\gamma$ and  tries to generate $\ket{\psi_{1^{i-1}1,\gamma}}$ by applying $G_{i,1,\gamma}G_{i-1,1,\gamma} \cdots G_{2,1,\gamma}G_{1,1,\gamma}$. If the prover fails to generate $\ket{\psi_{1^{i-1}1,\gamma}}$, he throws out everything and aborts by sending $\bot$ back.   On the fourth round,  If it's a testing round the prover reply with the $i$-th register of $\ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)$, where $\ext_i$ is specified in property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}. If it's the Hadamard round  the prover  runs $U$ and checks whether every copy except the $i$-th copy would be accepted. If all $m-1$ copies are accepted, he replies with the $i$-th copy, otherwise reply $\bot$.

	%We denote the random variable the verifier would get on the Hadamard round as $z_{composite}$. Also define $(d,z_{composite}) \defeq (\Acc, z_{composite}) + (1-|z_{composite}|)(\Rej,\bot)$ \hannote{correct notation?}

	Denote the result we would get when $c=1$ by $z_{composite,i}$. By construction, when $G_{i,1,\gamma}\ldots G_{1,1,\gamma}$ succeeded, the corresponding output would be $z_{good,i}$. Also note that this is the only case where the verifier won't reject, so $z_{composite,i}=z_{good,i}$.

	By property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}, the above strategy is accepted with probability $1-\negl(n)$ when the prover didn't abort.
	Since the prover's strategy is also efficient, by Lemma~\ref{lem:naive-qpip0-binding},
	$z_{composite}$ is $O(\eps)$-computationally indistinguishable to $z_{ideal, i}$.
\end{proof}

Now we try to put together all $i\in [m]$. First let
$$z=\frac{1}{m} \sum_i z_i= \frac{1}{m} \sum_i \sum_z \proj{z} \cdot \vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi}$$
which is the output distribution of $\PiSampZ$.
We also define the following accordingly:
$$z_{good}\defeq \frac{1}{m}\sum_i z_{good,i}$$
$$z_{ideal}\defeq \frac{1}{m}\sum_i z_{ideal,i}$$
Notice that $z_{ideal}$ is some ideal output distribution, which might not have the same accept probability as $z$.

\begin{theorem}
	Under the QLWE assumption, $\PiSampZ$ is a computationally sound protocol for $\SampBQP$.
\end{theorem}
\begin{proof}
	By Property~\ref{property-partition-norm-sum} of Lemma~\ref{lem:partition2}, we have
	\begin{align} \label{eq:bad-term-sum}
		\norm{\ket{\psi}}^2 \geq& \norm{\ket{\psi_{0,\gamma}}}^2+\norm{\ket{\psi_{1,\gamma}}}^2 \nn \\
		\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
		\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{11,\gamma}}}^2 \nn \\
		\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
		\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{110,\gamma}}}^2 +\cdots  \nn \\
		&+ \norm{\ket{\psi_{1^{m-1}0,\gamma}}}^2+ \norm{\ket{\psi_{1^{m-1}1,\gamma}}}^2
	\end{align}

	We have
	\begin{align} \label{eq:z-z-good}
		\tr|z-z_{good}| =& \tr\L|\frac{1}{m}\sum_i (z_i-z_{good,i})\R| \nn \\
		\leq&  \frac{1}{m}\sum_i\tr| (z_i-z_{good,i})| \nn \\
		\leq&  \frac{1}{m}\sum_i\L[\E_{pk, y, \gamma}\L[\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}\R]+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)\R] \nn \\%%%%%%%%
		\leq&  \frac{1}{m}+ 2\frac{1}{\sqrt m}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R) \nn \\ %%%%%
		=&O\L( \frac{1}{\sqrt m}+\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)
	\end{align}

	where we used triangle inequality on the second line, \Cref{thm:zi-zgoodi} on the third line, Equation~\ref{eq:bad-term-sum} and Cauchy's inequality on the fourth line.
	Let $m=O(1/\eps^2), T=O(1/\eps^2),\gamma_0=\eps^8$ and by triangle inequality we have $\tr\abs{z-z_{ideal}}=O(\varepsilon)$.
	Since $z$ is close to some ideal output distribution $z_{ideal}$, it must be close to the ideal output distribution with its own accept probability too.
\end{proof}
