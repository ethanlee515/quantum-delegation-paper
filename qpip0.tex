\section{$\SampBQP$ Delegation Protocol for Fully Classical Client}
\label{sec:qpip0_all}

In this section, we combine the core protocol from \cite{FOCS:Mahadev18a}, which we restate as Protocol~\ref{proto:urmila4}, with \Cref{QPIP1thm} to create a delegation protocol for $\SampBQP$ for fully classical clients. A direct composition results in Protocol~\ref{proto:qpip0_naive}. However, as we will see in \Cref{sec:urmila4}, Protocol~\ref{proto:urmila4} has a peculiar and weak guarantee, so \Cref{proto:qpip0_naive} don't have any reasonable completeness and soundness. To boost its soundness, we run $m=\poly(\lambda)$ copies in parallel and test on $m-1$ copies of them, resulting in Protocol~\ref{proto:QPIP0samp}. We use techniques from \cite{arXiv:ChiaChungYam19} to prove that Protocol~\ref{proto:QPIP0samp} has soundness error $1/\sqrt{m}$.

\subsection{Mahadev's measurement protocol}\label{sec:urmila4}

In her groundbreaking work, Mahadev~\cite{FOCS:Mahadev18a} gives a $\QPIP_0$ protocol for $\BQP$ languages.
The core of this work is a 4-round $\QPIP_0$ protocol $\PiMeasure$ that lets a $\BQP$ machine ``commit a $XZ$ measurement" to a classical machine.
Intuitively, the verifier chooses a string $h$ specifying the measurements he wants to make, and generates keys $pk, sk$ from $h$, before sending $pk$ to the prover. The prover commits to a state $\rho$ of its choice using $pk$ and replies with its commitment. The verifier then uniformly chooses between two options: do a \emph{testing round} or do a \emph{Hadamard round}. He sends his choice to the prover, and prover replies accordingly. If the verifier chose testing, he checks the prover's reply against the previous commitment, and rejects if he sees an inconsistency. If the verifier chose the Hadamard round, he calculates $M_{XZ}(\rho, h)$ based on the reply. \cite{FOCS:Mahadev18a} shows a ``binding" property of $\PiMeasure$: if a prover would always succeed on the testing round, then there exists some $\rho$ so that the verifier obtains $M_{XZ}(\rho, h)$ if he had chosen Hadamard round, no matter what $h$ the verifier has picked at the beginning.

We now formally describe the interface of $\PiMeasure$ while omitting the implementation details.

\begin{protocol}{Mahadev's measurement protocol $\PiMeasure=(\PMeasure, \VMeasure)$}
	\label{proto:urmila4}

	Inputs:
	\begin{itemize}
		\item Common input: Security parameter $1^\lambda$ where $\lambda\in\bbN$.
		\item Prover's input: a state $\rho\in\cB^{\otimes n}$ for the verifier to measure.
		\item Verifier's input: the measurement basis choice $h \in \zo^n$
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:measure1} The verifier generates a public and secret key pair $(pk, sk)\leftarrow\cVMeasure{1}(1^\lambda, h)$. It sends $pk$ to the prover.
		\item \label{step:measure2} The prover generates $(y, \sigma)\leftarrow\cPMeasure{2}(pk, \rho)$.
			$y$ is a classical ``commitment", and $\sigma$ is some internal state.
			He sends $y$ to the verifier.
		\item \label{step:measure3} The verifier samples $c\xleftarrow{\$}\zo$ uniformly at random and sends it to the prover. $c=0$ indicates a \emph{testing round}, while $c=1$ indicates a \emph{Hadamard round}.
		\item \label{step:measure4} The prover generates a classical string $a\leftarrow\cPMeasure{4}(pk, c, \sigma)$ and sends it back to the verifier.
		\item \label{step:output} If it is a testing round ($c=0$), then the verifier generates and outputs $o\leftarrow\cVMeasure{T}(pk, y, a)$ where $o\in\set{\Acc, \Rej}$.
			If it is a Hadamard round ($c=1$), then the verifier generates and outputs $v\leftarrow\cVMeasure{H}(sk, h, y, a)$.
	\end{enumerate}
\end{protocol}

$\PiMeasure$ has negligible completeness errors.
On the other hand, as the verifier learns the measurement outcome only on Hadamard round, the protocol offers no standard soundness guarantees;
instead, it achieves the following \emph{binding property} that gives weaker guarantees against cheating provers.

\begin{lemma}[binding property of $\PiMeasure$]
	\label{lem:urmila-binding}
	Let $\PMeasureStar$ be a $\BQP$ cheating prover for $\PiMeasure$ and $\lambda$ be the security parameter. Under the QLWE assumption, if $\PMeasureStar$ passes the testing round with probability $1-\negl(\lambda)$, then there exists some $\rho$ so that for all verifier's input $h \in \zo^n$, the verifier's outputs on the Hadamard round is computationally indistinguishable from $M_{XZ}(\rho, h)$.
	\iffalse    
	Suppose that for all $\lambda\in\bbN$ and $h\in\zo^*$ \Ethan{or $\zo^n$?},
	$\PMeasureStar$ passes the testing round with probability $1-\negl(\lambda)$.
	Then, under the QLWE assumption, there exists some $\rho$ so that for all $h$,
	The verifier's output on the Hadamard round is $\negl(\lambda)$-computationally indistinguishable from $M_{XZ}(\rho, h)$.
	\fi
\end{lemma}

We now use $\PiMeasure$ to transform our $\QPIP_1$ Protocol for $\SampBQP$, $\PiSamp=(\PSamp, \VSamp)$, to a corresponding $\QPIP_0$ protocol $\PiNaive$.
Recall that in $\PiSamp$ the verifier takes $X$ and $Z$ measurements on the prover's message.
In $\PiNaive$ we let the verifier use $\PiMeasure$ to learn those measurement outcomes instead.

\begin{protocol}{Intermediate $\QPIP_0$ protocol $\PiNaive$ for a $\SampBQP$ problem $(D_x)_{x\in\set{0, 1}^*}$}
	\label{proto:qpip0_naive}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ where $\lambda\in\bbN$
		\item Error parameter $\eps\in(0, 1)$
		\item Classical input $x\in\zo^n$ to the $\SampBQP$ instance
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:naive1} The verifier chooses a $XZ$-measurement $h$ from the distribution specified in \stepref{qpip1-verify} of $\PiSamp$.
		\item \label{step:naive2} The prover prepares $\rho$ by running \stepref{qpip1-state-gen} of $\PiSamp$.
		\item \label{step:urmila-in-naive}
			The verifier and prover run $(\PMeasure(\rho), \VMeasure(h))(1^\lambda)$.
			\begin{enumerate}
				\item The verifier samples $(pk, sk)\leftarrow\cVNaive{1}(1^\lambda, h)$ and sends $pk$ to the prover.
				\item The prover runs $(y, \sigma)\leftarrow\cPNaive{2}(pk, \rho)$ and sends $y$ to the verifier.
					Here we allow the prover to abort by sending $y=\bot$, which does not benefit cheating provers but is useful for analysis.
				\item\label{step:c-urmila-in-naive} The verifier samples $c\xleftarrow{\$}\zo$ and sends it to the prover.
				\item The prover replies $a\leftarrow\cPNaive{4}(pk, c, \sigma)$.
				\item
					If it is a testing round, the verifier accepts or rejects based on the outcome of $\PiMeasure$.
					If it is a Hadamard round, the verifier obtains $v$.
			\end{enumerate}
		\item \label{step:naive-output} If it's a Hadamard round, the verifier finishes the verification step of Protocol~\ref{ProtoQPIP1} by generating and outputting $(d, z)$
	\end{enumerate}
\end{protocol}

There are several problems with using $\PiNaive$ as a $\SampBQP$ protocol. First, since the verifier doesn't get a sample if he had chosen the testing round in Step~\ref{step:c-urmila-in-naive}, the protocol has completeness error at least $1/2$. Moreover, since Protocol~\ref{proto:urmila4} does not check anything on the Hadamard round, a cheating prover can give up passing the testing round and breaks the commitment on the Hadamard round, with only a constant $1/2$ probability of being caught.
However, we can show that \Cref{proto:qpip0_naive} has a binding property similar to \Cref{proto:urmila4}.

\begin{theorem}[binding property of $\PiNaive$]
	\label{lem:naive-qpip0-binding}
	Let $\PNaiveStar$ be a cheating $\BQP$ prover for $\PiNaive$ and $\lambda$ be the security parameter.
	Under the QLWE assumption, if conditioned on $\PNaiveStar$ not aborting (ie. $y\ne\bot$), $\PNaiveStar$ passes the testing round with probability $1-\negl(\lambda)$,
	then the verifier's output in the Hadamard round is $O(\eps)$-computationally indistinguishable from $(d, z_{ideal})$.
\end{theorem}
\begin{proof}
	If the prover chooses $\rho$ as the maximally mixed state and executes the rest of the protocol honestly,
	it would be accepted in the testing round with probability $1-\negl(\lambda)$,
	but has negligible probability passing the verification after the Hadamard round.
	We call this the \emph{dummy strategy}.

	Now we construct another cheating $\BQP$ prover $\Pstar$ that is perfect and non-aborting as follows.
	For the second message, run $(y, \sigma)\leftarrow\cPNaiveStar{2}(pk, \rho)$.
	If $y\ne\bot$, then reply $y$;
	else, run the corresponding step of the dummy strategy and reply with its results.
	For the fourth message, if $y\ne\bot$, run and reply with $a\leftarrow\cPNaiveStar{4}(pk, c, \sigma)$;
	else, continue the dummy strategy.

	Observe that this $\Pstar$ passes testing round with overwhelming probability by construction,
	so we can apply \Cref{lem:urmila-binding} to the $\PiMeasure$ call to use its binding property (\Cref{lem:urmila-binding}).
	That is, there exists some $\rho$ such that $v=M_{XZ}(\rho, h)$.
	Combining it with $\PiSamp$'s soundness (\Cref{QPIP1thm}),
	we see that $(d', z')\leftarrow(\Pstar, \VNaive)(1^\lambda, 1^{1/\varepsilon}, x)$ is $\eps$-computationally indistinguishable to $(d', z_{ideal}')$.

	Now we relate $(d', z')$ back to $(d, z)$.
	First, conditioned on that $\PNaiveStar$ aborts, since dummy strategy will be rejected with overwhelming probability in Hadamard round,
	we have $(d', z')$ is $O(\varepsilon)$-computationally indistinguishable to $(\Rej, \bot)=(d, z)$.
	On the other hand, conditioned on $\PNaiveStar$ not aborting, clearly $(d, z)=(d', z')$.
	So $(d, z)$ is $O(\eps)$-computationally indistinguishable to $(d', z')$,
	which in turn is $\negl(\lambda)$-computationally indistinguishable to $d', z_{ideal}')$.
	So $\abs{d-d'}\leq O(\eps)$,
	and $(d, z_{ideal})$ is $O(\eps)$-computationally indistinguishable to $(d', z_{ideal}')$.
	Combining everything, we conclude that $(d, z)$ is $O(\eps)$-computationally indistinguishable to $(d, z_{ideal})$.
\end{proof}

\subsection{$\QPIP_0$ protocol for $\SampBQP$} \label{sec:qpip0}

We now introduce our $\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$.
It is essentially a $m$-fold parallel repetition of $\PiNaive$.
Instead of having each copy running testing round or Hadamard round uniformly at random, we randomly pick one copy to run Hadamard round to get our samples, and run testing round on all other $m-1$ copies.
In the description of our protocol below, we describe $\PiNaive$ and $\PiMeasure$ in details in order to introduce notations that we need in our analysis.

\begin{protocol}{$\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$}
	\label{proto:QPIP0samp}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ for $\lambda\in\bbN$.
		\item Accuracy parameter $1^{1/\eps}$ for the $\SampBQP$ instance
		\item Input $x\in\zo^{\poly(\lambda)}$ for the $\SampBQP$ instance
	\end{itemize}

	Ingredient: Let $m=O(1/\eps^2)$ be the number of parallel repetitions to run.

	Protocol:
	\begin{enumerate}
		\item The verifier generates $m$ independently copies of basis choices $\vec{h}=(h_1,\ldots,h_m)$ as in \stepref{naive1} of $\PiNaive$.
		\item The prover prepares $\rho^{\otimes m}$; each copy of $\rho$ is prepared as in \stepref{naive2} of $\PiNaive$.
		\item The verifier generates $m$ key pairs for $\PiMeasure$, $\vec{pk}=(pk_1,\ldots,pk_m)$ and $\vec{sk}=(sk_1,\ldots,sk_m)$, as in \stepref{measure1} of $\PiMeasure$.
			It sends $\vec{pk}$ to the prover.
		\item The prover generates $\vec{y}=(y_1,\ldots,y_m)$ and $\sigma$ as in \stepref{measure2} of $\PiMeasure$.
			It sends $\vec{y}$ to the verifier.
		\item The verifier samples $r\xleftarrow{\$}[m]$ which is the copy to run Hadamard round for.
			For $1\leq i\leq m$, if $i\ne r$ then set $c_i\leftarrow 0$, else set $c_i\leftarrow 1$.
			It sends $\vec{c}=(c_1,\ldots,c_m)$ to the prover.
		\item The prover generates $\vec{a}$ as in \stepref{measure4} of $\PiMeasure$, and sends it back to the verifier.
		\item \label{step:multi-testing}
			The verifier computes the outcome for each round as in \stepref{naive-output} of $\PiNaive$.
			If any of the testing round copies are rejected, the verifier outputs $(\Rej, \bot)$.
			Else, it outputs the result from the Hadamard round copy.
	\end{enumerate}
\end{protocol}

Clearly $\PiSampZ$ is a $\QPIP_0$ protocol for $\SampBQP$ with negligible completeness error.
We now show that it is computationally sound.
\Ethan{Try to word the following a bit better}
The intuition is that the we run $m$ copies of the naive $\QPIP_0$ and do testing on randomly chosen $m-1$ copies of them, and do Hadamard round and calculate results from the remaining one copy. Therefore if the prover want to cheat, i.e. send something not binding in the Hadamard round copy, he would be caught with probability $1-1/m$. However, the prover might create correlations between copies that let him cheat with probability much higher than $1/m$. We are able to bound the soundness error as $O(1/\sqrt{m})$. To prove that, we use the following partition lemma from \cite{arXiv:ChiaChungYam19}, which intuitively says that for each $i\in[m]$, there exist two efficient ``projectors" \footnote{Actually they are not projectors, but for the simplicity of this discussion let's assume they are.} $G_{0,i}$ and $G_{1,i}$ in the prover's internal space with $G_{0,i}+G_{1,i} \approx Id$. $G_{0,i}$ represents the subspace that are rejected with high probability in the testing round of $i$-th copy, while $G_{1,i}$  represents the subspace accepted with high probability\footnote{This is also not technically correct as we will discuss later.} in the testing round of $i$-th copy.
Also as a careful reader might have noticed, the prover's space don't happen to split nicely into parts of very high accept probability in the testing round and parts with very low accept probability, as there will always be something in the middle. In \cite{arXiv:ChiaChungYam19} this is solved by doing eigenvalue estimation to calculate the accept probability, then split the space into parts that are accepted with probability higher or lower than a small threshold $\gamma$. However, states with accept probability really close to the threshold $\gamma$ can not be classified, so we need to average over randomly chosen $\gamma$ to have $G_{0,i}+G_{1,i} \approx Id$.

\begin{lemma}[partition lemma; revision of Lemma 3.5 of \cite{arXiv:ChiaChungYam19}\footnote{$G_{0}$ and $G_{1}$ of this version are created from doing $G$ of \cite{arXiv:ChiaChungYam19} and post-select on the $ph,th,in$ register being $0^t01$ or $0^t11$ then discard $ph,th,in$. Property~\ref{property:partition-err} corresponds to Property~1. Property~\ref{property:partition-testing} corresponds to Property~4, with $2^{m-1}$ changes to $m-1$ because we only have $m$ possible choices of $\{c\}$. Property~\ref{property:partition-binding} corresponds to Property~5. Property~\ref{property-partition-norm-sum} comes from the fact that $G_0$ and $G_1$ are post-selections of orthogonal results of the same $G$.}]\label{lem:partition2}
	Let $\lambda$ be the security parameter and  $\eps$ be the accuracy parameter. Let $(U_0,U)$ be a prover's strategy in a $m$-fold parallel repetition of $\PiMeasure$, where $U_0$ is how the prover generates $\vec{y}$ on the second message, and $U$ is how the prover generates $\vec{a}$ on the fourth message. Denote the string $0^{i-1}10^{m-i} \in \zo^m $ as $e_i$, which corresponds to Hadamard round on the $i$-th copy and testing round on all others. Let $\gamma_0 \in[0,1]$, and $T\in \mathbb{N}$ such that $\gamma_0=\poly(\eps)$ and $T=1/\poly(\eps)$.

	For all $i\in[m]$, $\gamma \in \L\{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}\R\}$, there exist two efficient quantum circuit $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ such that for all (possibly sub-normalized) $\poly(\lambda)$-qubits quantum state $\ket{\psi}_{\regX,\regZ}$,  

	\begin{align}
		G_{0,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{0,i,\gamma}}_{\regX,\regZ} \\ G_{1,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}  \\
		\ket{\psi}_{\regX,\regZ} =&   \ket{\psi_{0,i,\gamma}}_{\regX,\regZ}+ \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}+\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}
	\end{align}

	Note that $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ has failure probabilities, and this is reflected by the fact that $\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}$ and $\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}$ are  sub-normalized. $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ depend on $(U_0,U)$ and $\vec{pk},\vec{y}$.

	Furthermore, the following properties are satisfied for all $i\in[m]$.
	\begin{enumerate}
		\item \label{property:partition-err}  $$\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\|^2 \leq \frac{6}{T}+\negl(\lambda),$$

			where the averaged is over uniformly sampled $\gamma$. This also implies
			\begin{align}
				\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\| \leq \sqrt{\frac{6}{T}}+\negl(\lambda)
			\end{align}
			by Cauchy's inequality.

		\item \label{property:partition-testing}
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and  $j\neq i$, we have

			%      \begin{align*}
			%  \Pr\left[M_{\regX_i}\circ U\frac{\ket{\{c\}}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}\in \Acc_{pk_i,y_i}\right]\leq (m-1)\gamma+\negl(\secpar).
			%  \end{align*}

			%  Define
			%  $$\ket{\widetilde{\psi_{0,i,\gamma}}}\defeq U\frac{\ket{\{c\}}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}.$$
			%  We have
			%  \begin{align}
			%      \vev{\widetilde{\psi_{0,i,\gamma}}|P_{i,pk_i,y_i,acc}|\widetilde{\psi_{0,i,\gamma}}} \leq (m-1)\gamma+\negl(\secpar),
			%  \end{align}
			\begin{align}
				\norm{ P_{i,pk_i,y_i,acc} \circ U\frac{\ket{e_j}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}}^2 \leq (m-1)\gamma_0+\negl(\lambda),
			\end{align}
			where $P_{i,pk_i,y_i,acc}$ are projector to the states that $i$-th testing round accepts with $pk_i,y_i$, including the last measurement the prover did before sending $\vec{a}$.  This means that $\ket{\psi_{0,i,\gamma}}$ is rejected by the $i$-th testing round with high probability.
		\item \label{property:partition-binding}
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and $j\neq i$, there exists an efficient quantum algorithm $\ext_i$ such that
			\begin{align}
				\norm{P_{i,pk_i,y_i,acc} \circ \ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)}^2 =1-\negl(\lambda).
			\end{align}

			% \begin{align*}  
			%   \Pr\left[M_{\regX_i}\circ \ext_i\left(\frac{\ket{\{c\}}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)\in \Acc_{pk_i,y_i}\right]=1-\negl(\secpar).
			%   \end{align*}
			This will imply that $\ket{\psi_{1,i,\gamma}}$ is binding to the $i$-th Hadamard round.

		\item \label{property-partition-norm-sum}
			For all $\gamma$,
			\begin{align}
				\norm{\ket{\psi_{0,i,\gamma}}}^2+ \norm{\ket{\psi_{1,i,\gamma}}}^2 \leq  \norm{\ket{\psi}}^2
			\end{align}
	\end{enumerate}
\end{lemma}

\Ethan{The following discussion is under construction}

By using \Cref{lem:partition2} iteratively, we can decompose the prover's internal state.
Let $\ket{\psi}$ be the state the prover holds before he receives $\vec{c}$;
\Ethan{WLOG $\ket{\psi}$ is pure, or maybe can purify?}
we denote the corresponding Hilbert space as $H_{\regX,\regZ}$.
For all $k\leq m$, $d\in \zo^k$, $\gamma\in\set{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}}$, and $\ket{\psi} \in H_{\regX,\regZ}$, define
$$\ket{\psi_{d,\gamma}}\defeq G_{d_k,k,\gamma}\ldots G_{d_2,2,\gamma} G_{d_1,1,\gamma} \ket{\psi}.$$
For example, $\ket{\psi_{110, \gamma}}$ intuitively corresponds to the component that would pass the first two copies' testing rounds and fail the third one.
At this point it is tempting to decompose $\ket{\psi}$ into $\ket{\psi_{s, \gamma}}$ where $s\in\zo^m$ and say that $\ket{\psi_{1^m, \gamma}}$ is the only component that is not rejected with high ($1-1/m$) probability;
however, $G_{1,i}$ don't commute with $G_{1,j}$, so $\ket{\psi_{1^m, \gamma}}$ is only binding for the $m$-th copy.
Instead, we must make a point-wise argument for each $i\in[m]$, then... \Ethan{TODO}

For all $i\in[m]$, we define
\begin{align} \label{eq:partition-string}
	\ket{\psi} =& \ket{\psi_{0,\gamma}}+\ket{\psi_{1,\gamma}}+\ket{\psi_{err,1,\gamma}} \nn \\
	=& \ket{\psi_{0,\gamma}}+\ket{\psi_{10,\gamma}}+\ket{\psi_{11,\gamma}}+\ket{\psi_{err,1,\gamma}}+\ket{\psi_{err,2,\gamma}} \nn \\
	=& \ket{\psi_{0,\gamma}}+\ket{\psi_{10,\gamma}}+\ket{\psi_{110,\gamma}}+\cdots+\ket{\psi_{1^{m-1}0,\gamma}}+\ket{\psi_{1^{m-1}1,\gamma}} \nn \\
	&+\ket{\psi_{err,1,\gamma}}+\ket{\psi_{err,2,\gamma}}+\cdots+\ket{\psi_{err,m,\gamma}} \nn\\
	=&\sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
\end{align}
where we abuse the notation and use $\ket{\psi_{err,i,\gamma}}$ to denote the error state we get from decomposing $\ket{\psi_{1^{i-1},\gamma}}$.

We denote the projector in $H_{\regX,\regZ}$ corresponding to outputting string $z$ when doing Hadamard on $i$-th copy as $P_{acc,i,z}$.
Note that $P_{acc,i,z}$ also depends on $\vec{pk}, \vec{y}$, and $(sk_i, h_i)$ since it includes the measurement the prover did before sending $\vec{a}$,  verifier's checking on $(m-1)$ copies of testing rounds, and  the verifier's final computation from $(sk_i,h_i,y_i,a_i)$.

We denote the string $0^{i-1}10^{m-i} \in \zo^m$ as $e_i$. The output string corresponding to $\ket{\psi} \in H_{\regX,\regZ}$ when $c=e_i$ is then
$$z_i\defeq \E_{pk,y} \sum_z \norm{P_{acc,i,z} U\ket{e_i,\psi}}^2\proj{z},$$
where $\ket{e_i,\psi}=\ket{e_i}_\regC\ket{\psi}_{\regX,\regZ}$ and $U$ is the unitary the prover applies on the last round.
Note that we have averaged over $\vec{pk}, \vec{y}$ where as previously everything has fixed $\vec{pk}$ and $\vec{y}$.
\Ethan{Here $y$ is implicitly dependent on $pk$. Might need to clarify what the expected value over $y$ means?}
Now we define
\begin{align}
	z_{good, i}=\E_{\gamma, pk, y} \sum_z \norm{P_{acc,i,z} U\ket{e_i,\psi_{1^{i-1}1,\gamma}}}^2\proj{z}
\end{align}
which we can show is close to $z_i$.
However, before doing so, we first present a couple lemmas that we will need.
\begin{lemma}\label{lem:samp-tech}
	For any state $\ket{\psi}$,  $\ket{\phi}$ and projectors $\{P_z\}$ such that $\sum_z P_z \leq Id$ and $P_z P_{z'} =0 $ for all $z\neq z'$, we have
	$$  \sum_z |\vev{\psi|P_z|\phi}| \leq \norm{\psi}\norm{\phi} $$
\end{lemma}
\begin{proof}
	\begin{align}
		\sum_z |\vev{\psi|P_z|\phi}| =&\sum_z|\vev{\psi|P_zP_z|\phi}| \nn \\
		\leq& \sum_z \norm{\bra{\psi}P_z} \norm{ P_z\ket{\phi}} \nn \\
		\leq&  \sqrt{\sum_z \norm{P_z\ket{\psi}}^2} \sqrt{\sum_z\norm{P_z\ket{\phi}}^2} \nn \\
		\leq& \sqrt{\norm{\sum_z P_z\ket{\psi}}^2 } \sqrt{\norm{\sum_z P_z\ket{\phi}}^2 } \nn \\
		\leq & \norm{\ket{\psi}}\norm{\ket{\phi}},
	\end{align}
	where we used Cauchy's inequality on the second and third line and $P_z P_{z'} =0 $ on the fourth line.
\end{proof}
\begin{lemma}
	\label{lem:partition-testing}
	For all $\gamma\in\set{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}}$, and all $i,j\in[m]$ such that $j<i-1$, we have
	$$\norm{P_{acc,i,z} U \ket{e_i, \psi_{1^j0,\gamma}}}^2\leq (m-1)\gamma_0+\negl(n).$$
\end{lemma}
\begin{proof}
	Since the verifier only accepts if all $(m-1)$ copies of testing rounds accepts, for all $j\neq i$,
	$$P_{acc,i,z}=P_{acc,i,z}P_{j,pk_j,y_j,acc}.$$
	And therefore by Property~\ref{property:partition-testing} of Lemma~\ref{lem:partition2}, we have that for all $j <i-1$
	\begin{align} \label{eq:rejected-d}
		\norm{P_{acc,i,z} U \ket{e_i, \psi_{1^j0,\gamma}}}^2
		=& \norm{P_{acc,i,z}P_{j,pk_j,y_j,acc} U \ket{e_i}\, G_{0,j+1,\gamma}\ket{\psi_{1^j,\gamma}}  }^2 \nn \\
		\leq& \norm{P_{j,pk_j,y_j,acc} U \ket{e_i}\, G_{0,j+1,\gamma}\ket{\psi_{1^j,\gamma}}  }^2 \nn \\
		\leq& (m-1)\gamma_0+\negl(n)
	\end{align}
\end{proof}

Now we're ready to show that $z_{i, good}$ is close to $z_i$.

\begin{theorem}
	\label{thm:zi-zgoodi}
	$$\tr\abs{z_i-z_{i, good}}\leq\E_\gamma\L[\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}\R]+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)$$
\end{theorem}
\begin{proof}
	We rewrite \Cref{eq:partition-string}.
	$$\ket{\psi}=\E_{\gamma}\left[
		\sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
	\right]$$
	Then we expand $z_i$ as
	\begin{align}
		z_i=& z_{good,i}+ \E_\gamma \sum_z \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U   \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}+
		\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}  \R. \nn \\
		+&  \sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&  \bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U  \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&\L.   \sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} +\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}} \R] \proj{z} , \nn     
		%=& z_{good,i} +(\text{terms with } \psi_{1^j0},\, j\neq i ) + (\text{terms with } \psi_{1^{i-1}0}) +(\text{terms with }err )
	\end{align}
	where we omitted writing out $e_i$.
	Therefore we have
	\begin{align*}
		\tr|z_i-z_{good,i}|\leq& \E_\gamma \sum_z \L[ \sum_{k=0}^{i-1} \sum_{j=0}^{i-1} \L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^j0,\gamma}} \R|+
		2 \sum_{k=0}^{i-1} \L|\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} \R|  \R. \\
		+& 2 \sum_{k=0}^{i-1}\sum_{j=1}^{i}\L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\ket{\psi_{err,j,\gamma}}\R|    
		+2 \sum_{j=1}^{i}\L|\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \\
		+&\L. \sum_{k=1}^{i}\sum_{j=1}^{i}\L| \bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \R] \\ %%%%%%%%%
	\end{align*}
	by the triangle inequality.
	The last three error terms sum to $O\L(\frac{m^2}{\sqrt{T}}\R)$ by \Cref{lem:samp-tech} and \Cref{property:partition-err} of \Cref{lem:partition2}.

	Now by \Cref{lem:samp-tech} and \Cref{lem:partition-testing}, we see that
	\begin{align*}
		\sum_z \sum_{k=0}^{i-1}\sum_{j=0}^{i-1}
		&\abs{\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^j0,\gamma}}} \\
		&\leq\sum_z \abs{\bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^{i-1}0,\gamma}}} + O\L(m^2(m-1)\gamma_0\R) \\
		&\leq\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2 + O\L(m^2(m-1)\gamma_0\R)
	\end{align*}
	and similarly
	\begin{align*}
		\sum_z\sum_{k=0}^{i-1}
		&\abs{\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}}\\
		&\leq\sum_z\abs{\bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}}+O\L(m\sqrt{(m-1)\gamma_0}\R)\\
		&\leq\norm{\ket{\psi_{1^i,\gamma}}}+O\L(m\sqrt{(m-1)\gamma_0}\R)
	\end{align*}
\end{proof}

Now let $z_{true}$, as a mixed state, be correctly sampled from the $\SampBQP$ instance $D_x$,
and let $z_{ideal, i}=\tr(z_{good, i})z_{true}$.
We show that $z_{ideal, i}$ is close to $z_{good, i}$.
\begin{theorem}
	\label{thm:zgood-zideal}
	$\tr\abs{z_{good, i}-z_{ideal, i}}\leq O(\varepsilon)$
	\Ethan{This doesn't seem true; I think we get computational guarantees here at best?}
\end{theorem}
\begin{proof}
	For every $i\in [m]$ and every prover strategy $(U_0,U)$ for Protocol~\ref{proto:QPIP0samp}, consider the following composite strategy of the prover for the naive $\QPIP_0$ Protocol, Protocol~\ref{proto:qpip0_naive}. Note that the prover only interact with the verifier in Step~\ref{step:urmila-in-naive} of Protocol~\ref{proto:qpip0_naive} where Protocol~\ref{proto:urmila4} is run, so we describe the prover's action in turns of the four rounds of communication in Protocol~\ref{proto:urmila4}.

	The prover tries to run $U_0$ by taking the verifier's input as $i$-th copy of Protocol~\ref{proto:urmila4} in Protocol~\ref{proto:QPIP0samp} and simulating other $m-1$ copies by himself. The prover then picks a uniformly random $\gamma$ and  tries to generate $\ket{\psi_{1^{i-1}1,\gamma}}$ by applying $G_{i,1,\gamma}G_{i-1,1,\gamma} \cdots G_{2,1,\gamma}G_{1,1,\gamma}$. If the prover fails to generate $\ket{\psi_{1^{i-1}1,\gamma}}$, he throws out everything and aborts by sending $\bot$ back.   On the fourth round,  If it's a testing round the prover reply with the $i$-th register of $\ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)$, where $\ext_i$ is specified in property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}. If it's the Hadamard round  the prover  runs $U$ and checks whether every copy except the $i$-th copy would be accepted. If all $m-1$ copies are accepted, he replies with the $i$-th copy, otherwise reply $\bot$.

	%We denote the random variable the verifier would get on the Hadamard round as $z_{composite}$. Also define $(d,z_{composite}) \defeq (\Acc, z_{composite}) + (1-|z_{composite}|)(\Rej,\bot)$ \hannote{correct notation?}

	Denote the result we would get when $c=1$ by $z_{composite,i}$. By construction, when $G_{i,1,\gamma}\ldots G_{1,1,\gamma}$ succeeded, the corresponding output would be $z_{good,i}$. Also note that this is the only case where the verifier won't reject, so $z_{composite,i}=z_{good,i}$.

	By property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}, the above strategy is accepted with probability $1-\negl(n)$ when the prover didn't abort. Since the prover's strategy is also efficient, by Lemma~\ref{lem:naive-qpip0-binding},
	$\tr\abs{z_{composite,i}-z_{ideal,i}}=O(\eps)$.
\end{proof}

Now we try to put together all $i\in [m]$. First let
$$z=\frac{1}{m} \sum_i z_i= \frac{1}{m} \sum_i \sum_z \proj{z} \cdot \vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi}$$
which is the output distribution of $\PiSampZ$.
We also define the following accordingly:
$$z_{good}\defeq \frac{1}{m}\sum_i z_{good,i}$$
$$z_{ideal}\defeq \frac{1}{m}\sum_i z_{ideal,i}$$
Notice that $z_{ideal}$ is some ideal output distribution, which might not have the same accept probability as $z$.

\begin{theorem}
	Under the QLWE assumption, $\PiSampZ$ is a computationally sound protocol for $\SampBQP$.
\end{theorem}
\begin{proof}
	By Property~\ref{property-partition-norm-sum} of Lemma~\ref{lem:partition2}, we have
	\begin{align} \label{eq:bad-term-sum}
		\norm{\ket{\psi}}^2 \geq& \norm{\ket{\psi_{0,\gamma}}}^2+\norm{\ket{\psi_{1,\gamma}}}^2 \nn \\
		\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
		\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{11,\gamma}}}^2 \nn \\
		\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
		\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{110,\gamma}}}^2 +\cdots  \nn \\
		&+ \norm{\ket{\psi_{1^{m-1}0,\gamma}}}^2+ \norm{\ket{\psi_{1^{m-1}1,\gamma}}}^2
	\end{align}

	We have
	\begin{align} \label{eq:z-z-good}
		\tr|z-z_{good}| =& \tr\L|\frac{1}{m}\sum_i (z_i-z_{good,i})\R| \nn \\
		\leq&  \frac{1}{m}\sum_i\tr| (z_i-z_{good,i})| \nn \\
		\leq&  \frac{1}{m}\sum_i\L[\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)\R] \nn \\%%%%%%%%
		\leq&  \frac{1}{m}+ 2\frac{1}{\sqrt m}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R) \nn \\ %%%%%
		=&O\L( \frac{1}{\sqrt m}+\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)
	\end{align}

	where we used triangle inequality on the second line, \Cref{thm:zi-zgoodi} on the third line, Equation~\ref{eq:bad-term-sum} and Cauchy's inequality on the fourth line.
	Let $m=O(1/\eps^2), T=O(1/\eps^2),\gamma_0=\eps^8$ and by triangle inequality we have $\tr\abs{z-z_{ideal}}=O(\varepsilon)$.
	Since $z$ is close to some ideal output distribution $z_{ideal}$, it must be close to the ideal output distribution with its accept probability too.
\end{proof}
