\section{$\SampBQP$ Delegation Protocol for Fully Classical Client}
\label{sec:qpip0_all}

In this section, we combine the core protocol from \cite{FOCS:Mahadev18a}, which we restate as Protocol~\ref{proto:urmila4}, with \Cref{QPIP1thm} to create a delegation protocol for $\SampBQP$ for fully classical clients. A direct composition results in Protocol~\ref{proto:qpip0_naive}. However, as we will see in \Cref{sec:urmila4}, Protocol~\ref{proto:urmila4} has a peculiar and weak guarantee, so \Cref{proto:qpip0_naive} don't have any reasonable completeness and soundness. To boost the soundness of Protocol~\ref{proto:qpip0_naive}, we run $m=\poly(\lambda)$ copies of Protocol~\ref{proto:qpip0_naive} in parallel and test on $m-1$ copies of them, resulting in Protocol~\ref{proto:QPIP0samp}. We use techniques from \cite{arXiv:ChiaChungYam19} to prove that Protocol~\ref{proto:QPIP0samp} has soundness error $1/\sqrt{m}$ in \Cref{thm:qpip0}.


\subsection{Notations and technical lemma}

We first introduce some tools that we'll use in our analysis.

\begin{definition}[$M_{XZ}(\rho,h)$]
	For any natural number $n$, $n$-bit string $h$, and $n$-qubit quantum state $\rho$, consider the following measurement procedure: measure the first qubit of $\rho$ in $X$ basis if $h_1=0$; measure the first qubit of $\rho$ in $Z$ basis if $h_1=1$.  Measure the second qubit of $\rho$ in $X$ basis if $h_2=0$; measure the second qubit of $\rho$ in $Z$ basis if $h_2=1$. Continue qubit-by-qubit until all $n$-qubits of $\rho$ are measured, where $i$-th qubit is measured in $X$ basis if $h_i=0$ and  $i$-th qubit is measured in the $Z$ basis if $h_i=1$.

	We denote the $n$-bit random variable corresponding to the measurement results as $M_{XZ}(\rho,h)$.
\end{definition}

\Ethan{Moving the lemma up here for now so it doesn't break the flow later; maybe we can move it into preliminary?}
\begin{lemma}\label{lem:samp-tech}
	For any state $\ket{\psi}$,  $\ket{\phi}$ and projectors $\{P_z\}$ such that $\sum_z P_z \leq Id$ and $P_z P_{z'} =0 $ for all $z\neq z'$, we have
	$$  \sum_z |\vev{\psi|P_z|\phi}| \leq \norm{\psi}\norm{\phi} $$
\end{lemma}
\begin{proof}
	\begin{align}
		\sum_z |\vev{\psi|P_z|\phi}| =&\sum_z|\vev{\psi|P_zP_z|\phi}| \nn \\
		\leq& \sum_z \norm{\bra{\psi}P_z} \norm{ P_z\ket{\phi}} \nn \\
		\leq&  \sqrt{\sum_z \norm{P_z\ket{\psi}}^2} \sqrt{\sum_z\norm{P_z\ket{\phi}}^2} \nn \\
		\leq& \sqrt{\norm{\sum_z P_z\ket{\psi}}^2 } \sqrt{\norm{\sum_z P_z\ket{\phi}}^2 } \nn \\
		\leq & \norm{\ket{\psi}}\norm{\ket{\phi}},
	\end{align}
	where we used Cauchy's inequality on the second and third line and $P_z P_{z'} =0 $ on the fourth line.
\end{proof}

\subsection{Mahadev's measurement protocol}\label{sec:urmila4}

In her groundbreaking work, Mahadev~\cite{FOCS:Mahadev18a} gives a $\QPIP_0$ protocol for $\BQP$ languages.
The core of this work is a 4-round $\QPIP_0$ protocol $\PiMeasure$ that lets a $\BQP$ machine ``commit a $XZ$ measurement" to a classical machine.
Intuitively, the verifier chooses a string $h$ specifying  the measurement he wants to make, and sends encoded $h$ \Ethan{what?} to the prover. The prover ``commits" to a state $\rho$ with the encoded $h$ and replies. The verifier then uniformly chooses between two options: do a \emph{testing round} or do a \emph{Hadamard round}. He sends his choice between the two to the prover and has the  prover reply. If the verifier chose testing, he checks the prover's two replies and rejects if he sees an inconsistency. If the verifier chose the Hadamard round, he calculates $M_{XZ}(\rho,h)$ based on the replies. Mahadev~\cite{FOCS:Mahadev18a} proves a ``binding" property of the above protocol: if a prover's strategy would always succeeds on the testing round, then that strategy must binds to a $\rho$, meaning that no matter what $h$ the verifier has picked at the beginning, the verifier can get $M_{XZ}(\rho,h)$  with the same $\rho$ if he had chosen the Hadamard round.

We now formally describe the interface of $\PiMeasure$ while omitting the implementation details.

\begin{protocol}{Mahadev's measurement protocol $\PiMeasure=(\PMeasure, \VMeasure)$}
	\label{proto:urmila4}

	Inputs:
	\begin{itemize}
		\item Common input: Security parameter $1^\lambda$ where $\lambda\in\bbN$.
		\item Prover's input: a state $\rho\in\cB^{\otimes n}$ for the verifier to measure.
		\item Verifier's input:
			the measurement basis choice $h \in \{0,1\}^n$
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:measure1} The verifier generates a public and secret key pair $(pk, sk)\leftarrow\cVMeasure{1}(1^\lambda, h)$. It sends $pk$ to the prover.
		\item \label{step:measure2} The prover generates $(y, \sigma)\leftarrow\cPMeasure{2}(pk, \rho)$.
			$y$ is a classical ``commitment", and $\sigma$ is some internal state.
			He sends $y$ to the verifier.
		\item \label{step:measure3} The verifier samples $c\xleftarrow{\$}\zo$ uniformly at random and sends it to the prover. $c=0$ indicates a \emph{testing round}, while $c=1$ indicates a \emph{Hadamard round}.
		\item \label{step:measure4} The prover generates a classical string $a\leftarrow\cPMeasure{4}(pk, c, \sigma)$ and sends it back to the verifier.
		\item \label{step:output} If it is a testing round ($c=0$), then the verifier generates and outputs $o\leftarrow\cVMeasure{T}(pk, y, a)$ where $o\in\set{\Acc, \Rej}$.
			If it is a Hadamard round ($c=1$), then the verifier generates and outputs $v\leftarrow\cVMeasure{H}(sk, h, y, a)$.
	\end{enumerate}
\end{protocol}

The verifier only learns the measurement outcome on a Hadamard round.
The protocol achieves a ``binding" property that gives guarantees against cheating provers.

\begin{lemma}[binding property of $\PiMeasure$]
	\label{lem:urmila-binding}
	Let $\PMeasureStar$ be a $\BQP$ cheating  prover for $\PiMeasure$ and $\lambda$ be the security parameter. Under the QLWE assumption, if $\PMeasureStar$ passes the testing round with probability $1-\negl(\lambda)$, then there exists some $\rho$ so that for all verifier's input $h \in \zo^n$, the verifier's outputs on the Hadamard round is computationally indistinguishable from $M_{XZ}(\rho, h)$.
	\iffalse    
	Suppose that for all $\lambda\in\bbN$ and $h\in\zo^*$ \Ethan{or $\zo^n$?},
	$\PMeasureStar$ passes the testing round with probability $1-\negl(\lambda)$.
	Then, under the QLWE assumption, there exists some $\rho$ so that for all $h$,
	The verifier's output on the Hadamard round is $\negl(\lambda)$-computationally indistinguishable from $M_{XZ}(\rho, h)$.
	\fi
\end{lemma}

We also mention a fact that will be useful later.
\begin{fact}
	\label{lem:trivial-4-round-strategy}
	There exist a prover strategy for $\PiMeasure$ that is accepted with probability $1-\negl(\lambda)$
\end{fact}

We now use $\PiMeasure$ to transform our $\QPIP_1$ Protocol for $\SampBQP$, $\PiSamp=(\PSamp, \VSamp)$, to a corresponding $\QPIP_0$ protocol $\PiNaive$.
Recall that in $\PiSamp$ the verifier takes $X$ and $Z$ measurements on the prover's message.
In $\PiNaive$ we let the verifier use $\PiMeasure$ to learn those measurement outcomes instead.

\begin{protocol}{Intermediate $\QPIP_0$ protocol $\PiNaive$ for a $\SampBQP$ problem $(D_x)_{x\in\set{0, 1}^*}$}
	\label{proto:qpip0_naive}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ where $\lambda\in\bbN$
		\item Error parameter $\eps\in(0, 1)$
		\item Classical input $x\in\zo^n$ to the $\SampBQP$ instance
	\end{itemize}

	Protocol:
	\begin{enumerate}
		\item \label{step:naive1} The verifier chooses a $XZ$-measurement $h$ from the distribution specified in \stepref{qpip1-verify} of $\PiSamp$.
		\item \label{step:naive2} The prover prepares $\rho$ by running \stepref{qpip1-state-gen} of $\PiSamp$.
		\item \label{step:urmila-in-naive}
			The verifier and prover run $(\PMeasure(\rho), \VMeasure(h))(1^\lambda)$.
			\begin{enumerate}
				\item The verifier samples $(pk, sk)\leftarrow\cVNaive{1}(1^\lambda, h)$ and sends $pk$ to the prover.
				\item The prover runs $(y, \sigma)\leftarrow\cPNaive{2}(pk, \rho)$ and sends $y$ to the verifier.
					Here we allow the prover to abort by sending $y=\bot$, which does not benefit cheating provers but is useful for analysis.
				\item\label{step:c-urmila-in-naive} The verifier samples $c\leftarrow\xleftarrow{\$}\zo$ and sends it to the prover.
				\item The prover replies $a\leftarrow\cPNaive{4}(pk, c, \sigma)$.
				\item
					If it is a testing round, the verifier accepts or rejects based on the outcome of $\PiMeasure$.
					If it is a Hadamard round, the verifier obtains $v$.
			\end{enumerate}
		\item \label{step:naive-output} If it's a Hadamard round, the verifier finishes the verification step of Protocol~\ref{ProtoQPIP1} by generating and outputting $(d, z)$
	\end{enumerate}
\end{protocol}

There are several problems with using $\PiNaive$ as a $\SampBQP$ protocol. first, since the verifier doesn't get a sample if he had chosen the testing round in Step~\ref{step:c-urmila-in-naive}, so the protocol has  completeness error at least $1/2$. And since Protocol~\ref{proto:urmila4} does not check anything on the Hadamard round, a cheating prover can give up passing the testing round and breaks the commitment on the Hadamard round. Such cheating prover only has a constant $1/2$ probability of being caught, resulting in constant soundness error.

On the other hand, \Cref{proto:qpip0_naive} has a binding property like \Cref{proto:urmila4}, which we will use to achieve completeness and soundness in \Cref{sec:qpip0}.

\begin{lemma}[binding property of $\PiNaive$]
	\label{lem:naive-qpip0-binding}
	Let $\PNaiveStar$ be a cheating $\BQP$ prover for $\PiNaive$ and $\lambda$ be the security parameter.
	Under the QLWE assumption, if conditioned on $\PNaiveStar$ not aborting, $\PNaiveStar$ passes the testing round with probability $1-\negl(\lambda)$,
	then the verifier's output in the Hadamard round is $O(\eps)$-computationally indistinguishable from $(d, z_{ideal})$.
\end{lemma}
\begin{proof}
	Consider the following reduction to another cheating $\BQP$ prover for $\PiNaive$ that is perfect and non-aborting.

	We define $\Pstar$ as follows.
	For the second message, run $(y, \sigma)\leftarrow\cPNaiveStar{2}(pk, \rho)$.
	If $y\ne\bot$, then reply $y$;
	else, run the corresponding step of the dummy strategy as in \Cref{lem:trivial-4-round-strategy} and reply with its results.
	For the fourth message, if $y\ne\bot$, run and reply with $a\leftarrow\cPNaiveStar{4}(pk, c, \sigma)$;
	else, continue the dummy strategy.

	Observe that this $\Pstar$ passes testing round with overwhelming probability by construction,
	so we can apply \Cref{lem:urmila-binding} to the $\PiMeasure$ call to use its binding property (\Cref{lem:urmila-binding}).
	That is, there exists some $\rho$ such that $v=M_{XZ}(\rho, h)$.
	Combining it with $\PiSamp$'s soundness (\Cref{QPIP1thm}),
	we see that $(d', z')\leftarrow(\Pstar, \VNaive)(1^\lambda, 1^{1/\varepsilon}, x)$ is $\eps$-computationally indistinguishable to $(d', z_{ideal}')$.

	Now we relate $(d', z')$ back to $(d, z)$.
	First, for the case that $\PNaiveStar$ aborts, since dummy strategy will be rejected with high probability in Hadamard round,
	we have $(d', z')\approx_{c, O(\eps)}(\Rej, \bot)=(d, z)$ conditioned on $\PNaiveStar$ aborts.
	For the other case, conditioned on $\PNaiveStar$ not aborts, clearly $(d, z)=(d', z')$.
	So we have $(d, z)\approx_{c, O(\varepsilon)}(d', z')\approx_{c, \negl(\lambda)}(d', z_{ideal}')$,
	which in turn implies $\abs{d-d'}\leq O(\eps)$
	and $(d, z_{ideal})\approx_{c, O(\eps)}(d', z_{ideal}')$.
	Combining everything, we conclude that $(d, z)\approx_{c, O(\eps)}(d, z_{ideal})$.
\end{proof}

\subsection{$\QPIP_0$ protocol for $\SampBQP$} \label{sec:qpip0}

We now introduce our $\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$.
It is essentially a $m$-fold parallel repetition of $\PiNaive$.
Instead of having each copy running testing round or Hadamard round uniformly at random, we randomly pick one copy to run Hadamard round to get our samples, and run testing round on all other $m-1$ copies.
In the description of our protocol below, we describe $\PiNaive$ and $\PiMeasure$ in details  in order to introduce notations that we need in our analysis.

\begin{protocol}{$\QPIP_0$ protocol $\PiSampZ$ for $\SampBQP$}
	\label{proto:QPIP0samp}

	Inputs:
	\begin{itemize}
		\item Security parameter $1^\lambda$ for $\lambda\in\bbN$.
		\item Accuracy parameter $1^{1/\eps}$ for the $\SampBQP$ instance
		\item Input $x\in\zo^{\poly(\lambda)}$ for the $\SampBQP$ instance
	\end{itemize}

	Ingredient: Let $m=O(1/\eps^2)$ be the number of parallel repetitions to run.

	Protocol:
	\begin{enumerate}
		\item The verifier generates $m$ independently copies of basis choices $\vec{h}=(h_1,\ldots,h_m)$ as in \stepref{naive1} of $\PiNaive$.
		\item The prover prepares $\rho^{\otimes m}$; each copy of $\rho$ is prepared as in \stepref{naive2} of $\PiNaive$.
		\item The verifier generates $m$ key pairs for $\PiMeasure$, $\vec{pk}=(pk_1,\ldots,pk_m)$ and $\vec{sk}=(sk_1,\ldots,sk_m)$, as in \stepref{measure1} of $\PiMeasure$.
			It sends $\vec{pk}$ to the prover.
		\item The prover generates $\vec{y}=(y_1,\ldots,y_m)$ and $\sigma$ as in \stepref{measure2} of $\PiMeasure$.
			It sends $\vec{y}$ to the verifier.
		\item The verifier samples $r\xleftarrow{\$}[m]$ which is the copy to run Hadamard round for.
			For $1\leq i\leq m$, if $i\ne r$ then set $c_i\leftarrow 0$, else set $c_i\leftarrow 1$.
			It sends $\vec{c}=(c_1,\ldots,c_m)$ to the prover.
		\item The prover generates $\vec{a}$ as in \stepref{measure4} of $\PiMeasure$, and sends it back to the verifier.
		\item \label{step:multi-testing}
			The verifier computes the outcome for each round as in \stepref{naive-output} of $\PiNaive$.
			If any of the testing round copies are rejected, the verifier outputs $(\Rej, \bot)$.
			Else, it outputs the result from the Hadamard round copy.
	\end{enumerate}
\end{protocol}

\begin{theorem}\label{thm:qpip0}
	Assuming the QLWE assumption, $\PiSampZ$ is a $\QPIP_0$ protocol for all problems in $\SampBQP$ with negligible completeness error and computational soundness.
\end{theorem}

\Ethan{Mention that completeness is trivial somewhere up here}

The intuition behind this theorem is that the we send out $m$ independent copies of the naive $\QPIP_0$ and do testing on randomly chosen $m-1$ copies of them, and do Hadamard round and calculate results from the remaining one copy. Therefore if the prover want to cheat, i.e. send something not binding in the Hadamard round copy, he would be caught with probability $1-1/m$. However, the prover might create correlations between copies that let him cheat with probability much higher than $1/m$. This is a common problem in trying to create parallel repetition protocols. We are able to bound the soundness error as $O(1/\sqrt{m})$. To prove that, we use the following partition lemma from \cite{arXiv:ChiaChungYam19}, which intuitively says that for each $i\in[m]$, there exist two efficient ``projectors" \footnote{Actually they are not projectors, but for the simplicity of this discussion let's assume they are.} $G_{0,i}$ and $G_{1,i}$ in the prover's internal space with $G_{0,i}+G_{1,i} \approx Id$.  $G_{0,i}$ represents the subspace that are rejected with high probability in the testing round of $i$-th copy; $G_{1,i}$  represents the subspace accepted with ``high probability"\footnote{This is also not technically correct as we will discuss later.} in the testing round of $i$-th copy.  $G_{0,i}$ and $G_{1,i}$ need to be efficient because $\PiMeasure$ only gives computational security. Once we have $G_{0,i}$ and $G_{1,i}$, we can split up the prover's internal state $\ket{\psi}$ like conditional probabilistic events.  We  split up  $\ket{\psi}$ into $G_{0,1}\ket{\psi}+ G_{0,2}G_{1,1}\ket{\psi} + G_{0,3}G_{1,2}G_{1,1}\ket{\psi} + \dots +  G_{0,m} G_{1,m-1}\dots G_{1,2}G_{1,1}\ket{\psi} + G_{1,m} G_{1,m-1}\dots G_{1,2}G_{1,1}\ket{\psi}$, where for example, $G_{0,2}G_{1,1}\ket{\psi}$ intuitively corresponds to passing the testing round of the first copy then getting rejected on the testing round of the second copy. Since each of the  substates in  $\{G_{0,1}\ket{\psi}, G_{0,2}G_{1,1}\ket{\psi} , G_{0,3}G_{1,2}G_{1,1}\ket{\psi} , \dots ,  G_{0,m} G_{1,m-1}\dots G_{1,2}G_{1,1}\ket{\psi} \}$ all have  probability $1-1/m$ of being caught by one of the $m-1$ testing rounds, they have well-bounded 
 probability of being accepted in Step~\ref{step:multi-testing} of Protocol~\ref{proto:QPIP0samp}, so the output in  Step~\ref{step:multi-testing} would mostly corresponds to $G_{1,m} G_{1,m-1}\dots G_{1,2}G_{1,1}\ket{\psi}$. However, since $G_{1,i}$ don't commute with $G_{1,j}$, $G_{1,m} G_{1,m-1}\dots G_{1,2}G_{1,1}\ket{\psi}$ is only binding for the $m$-th copy, so this simplified strategy is not quite correct. We were able to fix this issue with a more careful split up of $\ket{\psi}$. Also as a careful reader might have noticed, the prover's space don't happen to split nicely into parts of very high accept probability in the testing round and parts with very low accept probability, as there will always be something in the middle. In \cite{arXiv:ChiaChungYam19} this is solved by doing eigenvalue estimation to calculate the accept probability, then split the space into parts that are accepted with probability higher or lower than a small threshold $\gamma$. However, states with accept probability really close to the threshold $\gamma$ can not be classified, so we need to average over randomly chosen $\gamma$ to have $G_{0,i}+G_{1,i} \approx Id$.

 %but there will always be some states  therefore we introduce  an extra parameter $\gamma$ that corresponds to the probability cut-off line that to distinguish the accepted and rejected part, and we need to average over $\gamma$.

 % We split the state sub-normalized states corresponding to the prover cheating on different copies and show that the sum of probabilities corresponding to bad states can't be more than $1/m$. {The actual proof is more complicated than this sketch because the $G$'s don't commute with each other, so we need to handle the splitting carefully.}

 %For example, $G_{0,3} G_{1,5} \ket{\psi}$ corresponds to the events of passing the testing round on the fifth copy then fails the testing round on the third copy.

 %Let $S_m$ be sets of $\{c\}$ such that only one of the $c_i=1$.
\begin{lemma}[partition lemma; revision of Lemma 3.5 of \cite{arXiv:ChiaChungYam19}\footnote{$G_{0}$ and $G_{1}$ of this version are created from doing $G$ of \cite{arXiv:ChiaChungYam19} and post-select on the $ph,th,in$ register being $0^t01$ or $0^t11$ then discard $ph,th,in$. Property~\ref{property:partition-err} corresponds to Property~1. Property~\ref{property:partition-testing} corresponds to Property~4, with $2^{m-1}$ changes to $m-1$ because we only have $m$ possible choices of $\{c\}$. Property~\ref{property:partition-binding} corresponds to Property~5. Property~\ref{property-partition-norm-sum} comes from the fact that $G_0$ and $G_1$ are post-selections of orthogonal results of the same $G$.}]\label{lem:partition2}
	Let $\lambda$ be the security parameter and  $\eps$ be the accuracy parameter. Let $(U_0,U)$ be a prover's strategy in a $m$-fold parallel repetition of $\PiMeasure$, where $U_0$ is how the prover generates $\vec{y}$ on the second message, and $U$ is how the prover generates $\vec{a}$ on the fourth message. Denote the string $0^{i-1}10^{m-i} \in \zo^m $ as $e_i$, which corresponds to Hadamard round on the $i$-th copy and testing round on all others. Let $\gamma_0 \in[0,1]$, and $T\in \mathbb{N}$ such that $\gamma_0=\poly(\eps)$ and $T=1/\poly(\eps)$.

	For all $i\in[m]$, $\gamma \in \L\{\frac{\gamma_0}{T},\frac{2\gamma_0}{T},\dots,\frac{T\gamma_0}{T}\R\}$, there exist two efficient quantum circuit $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ such that for all (possibly sub-normalized) $\poly(\lambda)$-qubits quantum state $\ket{\psi}_{\regX,\regZ}$,  

	\begin{align}
		G_{0,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{0,i,\gamma}}_{\regX,\regZ} \\ G_{1,i,\gamma}\ket{\psi}_{\regX,\regZ} \defeq& \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}  \\
		\ket{\psi}_{\regX,\regZ} =&   \ket{\psi_{0,i,\gamma}}_{\regX,\regZ}+ \ket{\psi_{1,i,\gamma}}_{\regX,\regZ}+\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}
	\end{align}

	% $$ \ket{\psi}_{\regX,\regZ} =  G_{0,i,\gamma}\ket{\psi}_{\regX,\regZ}+ G_{1,i,\gamma}\ket{\psi}_{\regX,\regZ}+\ket{\psi_{err}}_{\regX,\regZ},$$

	Note that $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ has failure probabilities, and this is reflected by the fact that $\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}$ and $\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}$ are  sub-normalized. $G_{0,i,\gamma}$ and $G_{1,i,\gamma}$ depend on $(U_0,U)$ and $\vec{pk},\vec{y}$.



	Furthermore, the following properties are satisfied for all $i\in[m]$.
	%
	\begin{enumerate}
		\item \label{property:partition-err}  $$\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\|^2 \leq \frac{6}{T}+\negl(\lambda),$$

			where the averaged is over uniformly sampled $\gamma$. This also implies
			\begin{align}
				\E_{\gamma}\|\ket{\psi_{err,i,\gamma}}_{\regX,\regZ}\| \leq \sqrt{\frac{6}{T}}+\negl(\lambda)
			\end{align}
			by Cauchy's inequality.

		\item \label{property:partition-testing}
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and  $j\neq i$, we have

			%      \begin{align*}
			%  \Pr\left[M_{\regX_i}\circ U\frac{\ket{\{c\}}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}\in \Acc_{pk_i,y_i}\right]\leq (m-1)\gamma+\negl(\secpar).
			%  \end{align*}

			%  Define
			%  $$\ket{\widetilde{\psi_{0,i,\gamma}}}\defeq U\frac{\ket{\{c\}}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}.$$
			%  We have
			%  \begin{align}
			%      \vev{\widetilde{\psi_{0,i,\gamma}}|P_{i,pk_i,y_i,acc}|\widetilde{\psi_{0,i,\gamma}}} \leq (m-1)\gamma+\negl(\secpar),
			%  \end{align}
			\begin{align}
				\norm{ P_{i,pk_i,y_i,acc} \circ U\frac{\ket{e_j}_{\regC}\ket{\psi_{0,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_0}_{\regX,\regZ}\|}}^2 \leq (m-1)\gamma_0+\negl(\lambda),
			\end{align}


			where $P_{i,pk_i,y_i,acc}$ are projector to the states that $i$-th testing round accepts with $pk_i,y_i$, including the last measurement the prover did before sending $\vec{a}$.  This means that $\ket{\psi_{0,i,\gamma}}$ is rejected by the $i$-th testing round with high probability.


		\item \label{property:partition-binding}

			% $\{c\}\in S_m$ such that $c_i = 0$
			For all $\vec{pk}$, $\vec{y}$, fixed $\gamma$, and $j\neq i$, there exists an efficient quantum algorithm $\ext_i$ such that

			\begin{align}
				\norm{P_{i,pk_i,y_i,acc} \circ \ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)}^2 =1-\negl(\lambda).
			\end{align}

			% \begin{align*}  
			%   \Pr\left[M_{\regX_i}\circ \ext_i\left(\frac{\ket{\{c\}}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)\in \Acc_{pk_i,y_i}\right]=1-\negl(\secpar).
			%   \end{align*}
			This will imply that    $\ket{\psi_{1,i,\gamma}}$ is binding to the $i$-th Hadamard round.

		\item \label{property-partition-norm-sum}
			For all $\gamma$,
			\begin{align}
				\norm{\ket{\psi_{0,i,\gamma}}}^2+ \norm{\ket{\psi_{1,i,\gamma}}}^2 \leq  \norm{\ket{\psi}}^2
			\end{align}

			% \item \hannote{added by me..not needed?}

			% $$\vev{\psi_{0,i,\gamma}|\psi_{1,i,\gamma}} = \negl(n)$$

	\end{enumerate}
\end{lemma}

\Ethan{Try to cut the proof into two: point-wise and average arguments. Figure out what does z-good mean intuitively.

Also more comments/remarks/discussions. Subnormalized state and stuff.}

\Ethan{Pull the definitions of $z_i$ and $z_{good, i}$ up here}



\Ethan{Mention completeness somewhere}

For soundness, We begin by considering the state $\ket{\psi}$ the prover in $\PiSampZ$ holds before he receives $\vec{c}$. We denote the corresponding Hilbert space as $H_{\regX,\regZ}$.
\Ethan{WLOG $\ket{\psi}$ is pure, or maybe can purify?}

For all $k\leq m$, $d\in \zo^k$, $\gamma$ \Ethan{domain for $\gamma$?}, and $\ket{\psi} \in H_{\regX,\regZ}$, define
$$\ket{\psi_{d,\gamma}}\defeq G_{d_k,k,\gamma}G_{d_{k-1},k-1,\gamma}\cdots G_{d_2,2,\gamma} G_{d_1,1,\gamma} \ket{\psi}$$

By Lemma~\ref{lem:partition2}, we can decompose
\begin{align} \label{eq:partition-string}
	\ket{\psi} =& \ket{\psi_{0,\gamma}}+\ket{\psi_{1,\gamma}}+\ket{\psi_{err,1,\gamma}} \nn \\
	=& \ket{\psi_{0,\gamma}}+\ket{\psi_{10,\gamma}}+\ket{\psi_{11,\gamma}}+\ket{\psi_{err,1,\gamma}}+\ket{\psi_{err,2,\gamma}} \nn \\
	=& \ket{\psi_{0,\gamma}}+\ket{\psi_{10,\gamma}}+\ket{\psi_{110,\gamma}}+\cdots+\ket{\psi_{1^{m-1}0,\gamma}}+\ket{\psi_{1^{m-1}1,\gamma}} \nn \\
	&+\ket{\psi_{err,1,\gamma}}+\ket{\psi_{err,2,\gamma}}+\cdots+\ket{\psi_{err,m,\gamma}},
\end{align}
where we abuse the notation and use $\ket{\psi_{err,i,\gamma}}$ to denote the error state we get from decomposing $\ket{\psi_{1^{i-1},\gamma}}$.

By Property~\ref{property-partition-norm-sum} of Lemma~\ref{lem:partition2}, we have
\begin{align} \label{eq:bad-term-sum}
	\norm{\ket{\psi}}^2 \geq& \norm{\ket{\psi_{0,\gamma}}}^2+\norm{\ket{\psi_{1,\gamma}}}^2 \nn \\
	\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
	\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{11,\gamma}}}^2 \nn \\
	\geq& \norm{\ket{\psi_{0,\gamma}}}^2+
	\norm{\ket{\psi_{10,\gamma}}}^2+ \norm{\ket{\psi_{110,\gamma}}}^2 +\cdots  \nn \\
	&+ \norm{\ket{\psi_{1^{m-1}0,\gamma}}}^2+ \norm{\ket{\psi_{1^{m-1}1,\gamma}}}^2
\end{align}

Denote the projector in $H_{\regX,\regZ}$ corresponding to outputting string $z$ when doing Hadamard on $i$-th copy as

$$P_{acc,i,z}.$$
Note that $P_{acc,i,z}$ also depends on $\vec{pk}, \vec{y}$, and $(sk_i, h_i)$ since it includes the measurement the prover did before sending $\vec{a}$,  verifier's checking on $(m-1)$ copies of testing rounds, and  the verifier's final computation from $(sk_i,h_i,y_i,a_i)$.

Since the verifier only accepts if all $(m-1)$ copies of testing rounds accepts, for all $j\neq i$,

$$P_{acc,i,z}=P_{acc,i,z}P_{j,pk_j,y_j,acc}.$$

And therefore by Property~\ref{property:partition-testing} of Lemma~\ref{lem:partition2}, we have that for all $j <i-1$

\begin{align} \label{eq:rejected-d}
	\norm{P_{acc,i,z} U \ket{e_i, \psi_{1^j0,\gamma}}}^2
	=& \norm{P_{acc,i,z}P_{j,pk_j,y_j,acc} U \ket{e_i}\, G_{0,j+1,\gamma}\ket{\psi_{1^j,\gamma}}  }^2 \nn \\
	\leq& \norm{P_{j,pk_j,y_j,acc} U \ket{e_i}\, G_{0,j+1,\gamma}\ket{\psi_{1^j,\gamma}}  }^2 \nn \\
	\leq& (m-1)\gamma_0+\negl(n)
\end{align}

Denote the string $0^{i-1}10^{m-i} \in \zo^m $ as $e_i$. The output string corresponding to $\ket{\psi} \in H_{\regX,\regZ}$ when $c=e_i$ is then

$$z_i\defeq \E_{pk,y} \sum_z \proj{z} \cdot \vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi},$$
where $\ket{e_i,\psi}=\ket{e_i}_\regC\ket{\psi}_{\regX,\regZ}$ and $U$ is the unitary the prover applies on the last round. Note that we have averaged over $\vec{pk}, \vec{y}$ where as previously everything has fixed $\vec{pk}$ and $\vec{y}$.
\Ethan{Here $\psi$ and $y$ are implicitly dependent on $pk$. Might need to clarify what the expected value over $y$ means.}

Define
\begin{align}
	z_{good,i}=\E_\gamma \sum_z \proj{z} \cdot \vev{e_i,\psi_{1^{i-1}1,\gamma}|U^\dag P_{acc,i,z} U|e_i,\psi_{1^{i-1}1,\gamma}}
\end{align}

\begin{theorem}
	\Ethan{First part of main theorem this section}
	$z_i\approx z_{good, i}$
\end{theorem}
\begin{proof}

	Splitting $\ket{\psi}$ with Equation~\ref{eq:partition-string},
	\hannote{gamma..}
	\Ethan{Maybe take expected value over gamma here}


	\begin{align}
		\ket{\psi}=& \L. \ket{\psi_{0,\gamma}}+\ket{\psi_{10,\gamma}}+\ket{\psi_{110,\gamma}}+\cdots+\ket{\psi_{1^{i-1}0,\gamma}}+
		\ket{\psi_{1^{i-1}1,\gamma}} \R. \nn \\
		+& \L.\ket{\psi_{err,1,\gamma}}+\ket{\psi_{err,2,\gamma}}+\cdots+\ket{\psi_{err,i,\gamma}}\R. \nn \\
		=& \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
	\end{align}

	we have

	\begin{align}
		z_i =& \sum_z \proj{z} \cdot \vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi} \nn \\
		=& \sum_z \proj{z} \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}} +\bra{\psi_{1^i,\gamma}} +\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} \R]U^\dag  P_{acc,i,z} U\nn \\
		&\L[ \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}\R]  \nn \\
		=& \E_\gamma \sum_z \proj{z} \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}} +\bra{\psi_{1^i,\gamma}} +\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} \R]U^\dag  P_{acc,i,z} U\nn \\
		&\L[ \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}} +\ket{\psi_{1^i,\gamma}} +\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}\R]  \nn \\
		=& z_{good,i}+ \E_\gamma \sum_z \proj{z} \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U   \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}+
		\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}  \R. \nn \\
		+&  \sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&  \bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U  \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&\L.   \sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} +\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}} \R] , \nn     
		%=& z_{good,i} +(\text{terms with } \psi_{1^j0},\, j\neq i ) + (\text{terms with } \psi_{1^{i-1}0}) +(\text{terms with }err )
	\end{align}

	%  U^\dag  P_{acc,i,z}U

	% \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
	% \ket{\psi_{1^i,\gamma}}
	% \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}  

	where we omitted writing out $e_i$ starting the second line. We have
	\begin{align} \label{eq:zi-zgoodi}
		&\tr|z_i-z_{good,i}|   \nn \\
		\leq&  \sum_z  \L| \E_\gamma \L[\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U   \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}+
		\sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}  \R. \R. \nn \\
		+&  \sum_{k=0}^{i-1} \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&  \bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}}
		+\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U  \sum_{j=0}^{i-1} \ket{\psi_{1^j0,\gamma}}
		\nn \\
		+&\L.\L. \sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}}
		+\sum_{k=1}^{i}\bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \sum_{j=1}^{i}\ket{\psi_{err,j,\gamma}} \R]\R| \nn \\  %%%%%%%%%%%
		\leq&  \sum_z   \E_\gamma \L[\sum_{k=0}^{i-1} \sum_{j=0}^{i-1} \L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U    \ket{\psi_{1^j0,\gamma}} \R|+
		2 \sum_{k=0}^{i-1} \L|\bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} \R|  \R.  \nn \\
		+&  2 \sum_{k=0}^{i-1}\sum_{j=1}^{i}\L| \bra{\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U\ket{\psi_{err,j,\gamma}}\R|    
		+2 \sum_{j=1}^{i}\L|\bra{\psi_{1^i,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \nn \\
		+&\L. \sum_{k=1}^{i}\sum_{j=1}^{i}\L| \bra{\psi_{err,k,\gamma}} U^\dag  P_{acc,i,z}U \ket{\psi_{err,j,\gamma}}\R| \R] \nn \\ %%%%%%%%%
		\leq&  \sum_z   \L[\sum_{k=0}^{i-1} \sum_{j=0}^{i-1} \L| \bra{e_i,\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U    \ket{e_i,\psi_{1^j0,\gamma}} \R|+
		2 \sum_{k=0}^{i-1} \L|\bra{e_i,\psi_{1^k0,\gamma}}U^\dag  P_{acc,i,z}U \ket{e_i,\psi_{1^i,\gamma}} \R|  \R]\nn \\
		+& O\L(\frac{m^2}{\sqrt T}\R)\nn \\ %%%%%%%%%
		\leq&  \sum_z   \L[\L| \bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U    \ket{\psi_{1^{i-1}0,\gamma}} \R|+
		2  \L|\bra{\psi_{1^{i-1}0,\gamma}}U^\dag  P_{acc,i,z}U \ket{\psi_{1^i,\gamma}} \R|  \R]    \nn \\ 
		+&O\L(\frac{m^2}{\sqrt T}+m^2{(m-1)\gamma_0}+m\sqrt{(m-1)\gamma_0}\R)\nn \\ %%%%%%%%%
		\leq& \norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R),
	\end{align}
where on the second inequality we used triangle inequality, on the third inequality we used  Lemma~\ref{lem:samp-tech} and property~\ref{property:partition-err} of Lemma~\ref{lem:partition2}, on the fourth inequality we used Lemma~\ref{lem:samp-tech} and Equation~\ref{eq:rejected-d}, and on the last inequality we used Lemma~\ref{lem:samp-tech}. Once again, we omit $e_i$ when it is not relevant.

\end{proof}

\begin{theorem}
	\Ethan{Second part of main theorem this section}
	$(d_i, z_{good, i})\approx (d_i, z_{ideal, i})$
	\Ethan{Need to define $d_i$ here}
\end{theorem}
\begin{proof}

	% \begin{align}
	%     &\vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi} \nn \\
	%     =& \bra{e_i, \psi_{1^{i-1}1,\gamma}} U^\dag P_{acc,i,z} U \ket{e_i\psi_{1^{i-1}1,\gamma}} +\hannote{poly terms?}+ \negl(n)
	% \end{align}

	For every $i\in [m]$ and every prover strategy $(U_0,U)$ for Protocol~\ref{proto:QPIP0samp}, consider the following composite strategy of the prover for the naive $\QPIP_0$ Protocol, Protocol~\ref{proto:qpip0_naive}. Note that the prover only interact with the verifier in Step~\ref{step:urmila-in-naive} of Protocol~\ref{proto:qpip0_naive} where Protocol~\ref{proto:urmila4} is run, so we describe the prover's action in turns of the four rounds of communication in Protocol~\ref{proto:urmila4}.

	The prover tries to run $U_0$ by taking the verifier's input as $i$-th copy of Protocol~\ref{proto:urmila4} in Protocol~\ref{proto:QPIP0samp} and simulating other $m-1$ copies by himself. The prover then picks a uniformly random $\gamma$ and  tries to generate $\ket{\psi_{1^{i-1}1,\gamma}}$ by applying $G_{i,1,\gamma}G_{i-1,1,\gamma} \cdots G_{2,1,\gamma}G_{1,1,\gamma}$. If the prover fails to generate $\ket{\psi_{1^{i-1}1,\gamma}}$, he throws out everything and aborts by sending $\bot$ back.   On the fourth round,  If it's a testing round the prover reply with the $i$-th register of $\ext_i\left(\frac{\ket{e_j}_{\regC}\ket{\psi_{1,i,\gamma}}_{\regX,\regZ}}{\|\ket{\psi_1}_{\regX,\regZ}\|}\right)$, where $\ext_i$ is specified in property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}. If it's the Hadamard round  the prover  runs $U$ and checks whether every copy except the $i$-th copy would be accepted. If all $m-1$ copies are accepted, he replies with the $i$-th copy, otherwise reply $\bot$.

	%We denote the random variable the verifier would get on the Hadamard round as $z_{composite}$. Also define $(d,z_{composite}) \defeq (\Acc, z_{composite}) + (1-|z_{composite}|)(\Rej,\bot)$ \hannote{correct notation?}

	Denote the result we would get when $c=1$ by $(d,z_{composite,i})$.

	By  property~\ref{property:partition-binding} of Lemma~\ref{lem:partition2}, the above strategy is accepted with probability $1-\negl(n)$ when the prover didn't abort. Since the prover's strategy is also efficient, by Lemma~\ref{lem:naive-qpip0-binding},
	\begin{align}
		(d,z_{composite,i})\approx_{c, O(\eps)}(d,z_{ideal,i})
	\end{align}

	\Ethan{Is this particular $z_{ideal, i}$ defined? As in, what's its corresponding accept probability?}

	By construction, when $G_{i,1,\gamma}G_{i-1,1,\gamma} \cdots G_{2,1,\gamma}G_{1,1,\gamma}$ succeeded, the corresponding output would be $z_{good,i}$. Also note that this is the only case where the verifier won't reject, so $(d,z_{composite,i})=(d,z_{good,i})$, where $(d,z_{good,i})$ is defined as:

	$$\begin{cases}
		(d,z_{good,i}) \la (\Acc, z_{good,i}/|z_{good,i}|) & \text{with probability } |z_{good,i}|\\
						(d,z_{good,i}) = (\Rej,\bot)  & \text{otherwise }
	\end{cases}$$.

	% where  $(d,z)_{good,i} \defeq (\Acc, z_{good,i}) + (1-|z_{good,i}|)(\Rej,\bot)$ \hannote{correct notation? operational def?} .

	Therefore

	\begin{align}
		(d,z_{good,i})\approx_{c, O(\eps)}(d,z_{ideal,i}).
	\end{align}
\end{proof}

\begin{theorem}
	\Ethan{TODO some kinda average argument}
\end{theorem}
\begin{proof}
	Now we try to put together all $i\in [m]$. Define
	$$z_{good}\defeq \frac{1}{m}\sum_i z_{good,i}.$$

	We have
	\begin{align} \label{eq:z-z-good}
		\tr|z-z_{good}| =& \tr\L|\frac{1}{m}\sum_i (z_i-z_{good,i})\R| \nn \\
		\leq&  \frac{1}{m}\sum_i\tr| (z_i-z_{good,i})| \nn \\
		\leq&  \frac{1}{m}\sum_i\L[\norm{\ket{\psi_{1^{i-1}0,\gamma}}}^2+ 2\norm{\ket{\psi_{1^{i-1}0,\gamma}}}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)\R] \nn \\%%%%%%%%
		\leq&  \frac{1}{m}+ 2\frac{1}{\sqrt m}+O\L(\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R) \nn \\ %%%%%
		=&O\L( \frac{1}{\sqrt m}+\frac{m^2}{\sqrt T}+m\sqrt{(m-1)\gamma_0}\R)
	\end{align}

	where we used triangle inequality on the second line, Equation~\ref{eq:zi-zgoodi} on the third line, Equation~\ref{eq:bad-term-sum} and Cauchy's inequality on the fourth line.

	We now proceed to prove that $z_{good}$ is close to the ideal distribution.
	Since $\vec{c}$ is drawn  from $e_i$ with uniformly random $i\in [m]$, we have
	$$z=\frac{1}{m} \sum_i z_i= \frac{1}{m} \sum_i \sum_z \proj{z} \cdot \vev{e_i,\psi|U^\dag P_{acc,i,z} U|e_i,\psi},$$
	where we represent the random variable $z$ as a real non-negative diagonal matrix, with the matrix entries begin \Ethan{typo?} probabilities. Note that $z$ is ``sub-normalized", i.e. $\tr (z) \leq 1 \text{}$, and $\tr(z)$ equals to the probability of getting accepted.

		\Ethan{Here use the 2nd thm}

	Average over $i\in[m]$ we get

	\begin{align}
		(d,z_{good})\approx_{c, O(\eps)}(d,z_{ideal}).
	\end{align}
	% \hannote{do we lose a factor of $m$?}
	Recall that by Eq~\ref{eq:z-z-good} we have $\norm{z-z_{good}}_1 \leq O(\eps)$ if we pick $m=O(1/\eps^2), T=O(1/\eps^2),\gamma_0=\eps^8$, which implies
	\begin{align}
		(d,z)\approx_{c, O(\eps)}(d,z_{good}).
	\end{align}

	Therefore  we have  
	\begin{align}
		(d,z)\approx_{c, O(\eps)}(d,z_{ideal}).
	\end{align}
\end{proof}
