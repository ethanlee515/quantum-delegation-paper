\section{Introduction}

Can quantum computation, with potential computational advantages that are intractable for classical computers,
be efficiently verified by classical means?
This problem has been a major open problems in quantum complexity theory and delegation of quantum computation~\cite{web:Aaronson}. A complexity-theoretic formulation of this problem by Gottesman in 2004~\cite{web:Aaronson} asks about the possibility for an efficient classical verifier (a $\BPP$ machine) to verify the output of an
efficient quantum prover (a $\BQP$ machine).
In the absence of techniques for directly tackling this question, earlier feasibility results on this problem have been focusing on two weaker formulations.
The first type of feasibility results (e.g.,~\cite{BFK09,arXiv:ABOEM17,FK17,mf16}) considers the case where the verifier is equipped with limited quantum power.
The second type of feasibility results (e.g,~\cite{Nat:RUV13, CGJV19, Gheorghiu_2015, HPF15})
considers a $\BPP$ verifier interacting with at least two entangled, non-communicating quantum provers.

Recently, the problem is resolved by a breakthrough result of Mahadev~\cite{FOCS:Mahadev18a}, who constructed the first Classical Verification of Quantum Computation (CVQC) protocol for $\BQP$, where an efficient classical ($\BPP$) verifier can interact with an efficient quantum ($\BQP$) prover to verify any $\BQP$ language. Soundness of Mahadev's protocol  is based on a widely recognized computational assumption that the learning with errors (LWE) problem~\cite{JACM:Regev09} is hard for $\BQP$ machines.
The technique invented therein has inspired many subsequent developments of CVQC protocols with improved parameters and functionality. For example, Mahadev's protocol has a large constant soundness error. The works of ~\cite{arXiv:AlaChiHun19,arXiv:ChiaChungYam19} use parallel repetition to achieve a negligible soundness error. As another example, the work of ~\cite{FOCS:GheVid19} extends Mahadev's techniques in an involved way to obtain a CVQC protocol with an additional blindness property.  

In this work, we make two more contributions to this exciting line of research. First, we observe that the literature has mostly restricted the attention to delegation of \emph{decision} problems (i.e., $\BQP$). Motivated by the intrinsic randomness of quantum computation and the sampling nature of many quantum applications, we initiate the study of CVQC for quantum \emph{sampling} problems. Second, we further investigate the desirable \emph{blindness} property and construct the first \emph{constant-round} blind CVQC protocols. We elaborate on our contributions in \Cref{subsection:sampling} and \ref{subsection:blind}, respectively.

\subsection{CVQC for Quantum Sampling Problems} \label{subsection:sampling}

We initiate the study of CVQC for quantum sampling problem, which we believe is highly desirable and natural for delegation of quantum computation. Due to the intrinsic randomness of quantum mechanics, the output from a quantum computation is randomized and described by a distribution. 
Thus, if a classical verifier want to utilize the full power of a quantum machine, the ability to get a verifiable sample from the quantum circuit's output distribution is desirable.  On a more concrete level, quantum algorithms like Shor's algorithm~\cite{Shor} has a significant quantum sampling component, and the recent quantum supremacy proposals (e.g.,~\cite{Boson, IQP, nature-google}) are built around sampling tasks, suggesting the importance of sampling in quantum computation.

It is worth noting that the difficulty of extending the delegation of decision problem to the delegation of sampling problems is quantum-specific. This is because 
there is a simple reduction from the delegation of \emph{classical} sampling problems to decision ones:  the verifier can sample and fix the random seed of the computation, 
which makes the computation deterministic. Then, the verifier can delegate the output of the computation bit-by-bit as decision problems. However, this derandomization trick does not work in the quantum setting due to its intrinsic randomness.

\vspace{-3pt}

\paragraph{Our Contribution.}
As the first step to formalize CVQC for quantum sampling problems, we consider the complexity class $\SampBQP$ introduced by Aaronson~\cite{aaronson_2013} as a natural class to capture efficiently computable quantum sampling problems. 
$\SampBQP$ consists of sampling problems $(D_x)_{x\in\zo^*}$ that can be approximately sampled by a $\BQP$ machine with a desired inverse polynomial error (See Section~\ref{sec:samp_definition} for the formal definition). We consider CVQC for a $\SampBQP$ problem $(D_x)_{x\in\zo^*}$ where a classical $\BPP$ verifier delegates the computation of a sample $z\leftarrow D_x$ for some input $x$ to a quantum $\BQP$ prover. Completeness requires that when the prover is honest, the verifier should accept with high probability and learn a correct sample $z\leftarrow D_x$. For soundness, intuitively, the verifier should not accept and output a sample with incorrect distribution  when interacting with a malicious prover. We formalize the soundness by a strong \emph{simulation-based} definition, (\Cref{dfn:stats-secure-proto-sampbqp}),
where we require that the joint distribution $(d,z)$ of the decision bit $d \in \set{\Acc, \Rej}$ and the output $z$ (which is $\bot$ when $d = \Rej$) is $\eps$-close (in  either statistical or computational sense) to an ``ideal distribution'' $(d,z_{ideal})$, where $z_{ideal}$ is sampled from the desired distribution $D_x$ when $d = \Acc$ and set to $\bot$ when $d = \Rej$.\footnote{This simulation-based formulation is analogous to the standard composable security definition for QKD.}

As our main result, we construct a constant-round CVQC protocol for $\SampBQP$, based on the quantum LWE (QLWE) assumption that the learning-with-errors problem is hard for BQP machines. 
\begin{theorem}[informal] \label{thm:qpip0-informal}
Assuming the QLWE assumption, there exists a four-message CVQC protocol for all sampling problems in $\SampBQP$ with computational soundness and negligible completeness error.
\end{theorem}

We note that since the definition of $\SampBQP$ allows an inverse polynomial error, our CVQC protocol also implicitly allows an arbitrary small inverse polynomial error in  soundness (see Section~\ref{sec:samp_definition} for the formal definition). Achieving negligible soundness error for delegating sampling problems is an intriguing open question; see Section~\ref{subsec:discussion} for further discussions.

The construction of our CVQC protocol follows the blueprint of Mahadev's construction~\cite{FOCS:Mahadev18a}. However, there are several obstacles we need to overcome along the way. To explains the obstacles and our ideas, we first present a high-level overview of Mahadev's protocol.

\paragraph{Overview of Mahadev's Protocol.}
Following~\cite{FOCS:Mahadev18a}, we define $\QPIP_{\tau}$ as classes of interactive proof systems between an (almost) classical verifier and a quantum prover, where the classical verifier has limited quantum computational capability, formalized as possessing $\tau$-qubit quantum memory.
A formal definition is given in Appendix~\ref{sec:qpip_def}. 

At a high-level, the heart of Mahadev's protocol is a measurement protocol $\PiMeasure$ that can compile an one-round $\QPIP_1$ protocol (with special properties) to a $\QPIP_0$ protocol. Note that in a $\QPIP_1$ protocol, the verifier with one-qubit memory can only measure the prover's quantum message qubit by qubit. Informally, the measurement protocol $\PiMeasure$ allows a $\BQP$ prover to ``commit to'' a quantum state $\rho$ and a classical verifier to choose an $X$ or $Z$ measurement to apply to each qubit of $\rho$ such that the verifier can learn the resulting measurement outcome. 

Thus, if an (one-round) $\QPIP_1$ verifier only applies $X$ or $Z$ measurement to the prover's quantum message, we can use the measurement protocol $\PiMeasure$ to turn the $\QPIP_1$ protocol into a $\QPIP_0$ protocol in a natural way. One additional requirement here is that the verifier's measurement choices need to be determined at the beginning (i.e., cannot depend adaptively on the intermediate measurement outcome). 

Furthermore, in $\PiMeasure$, the verifier chooses to run a ``\emph{testing}'' round or a ``\emph{Hadamard}'' round with $1/2$ probability, respectively. Informally, the testing round is used to ``test'' the commitment of $\rho$, and the Hadamard round is used to learn the measurement outcome. (See \Cref{proto:urmila4} for further details about the measurement protocol $\PiMeasure$.) Another limitation here is that in the testing round, the verifier only ``test'' the commitment without learning any measurement result. 

In~\cite{FOCS:Mahadev18a}, Mahadev's CVQC protocol for $\BQP$ is constructed by applying her measurement protocol to the one-round $\QPIP_1$ protocol of~\cite{PhysRevA.93.022326, mf16}, which has the desired properties that the verifier only performs non-adaptive $X/Z$ measurement to the prover's quantum message. The fact that the verifier does not learn the measurement outcome in the testing round is not an issue here since the verifier can simply accept when the test is passed (at the cost of a constant soundness error).

\paragraph{Overview of Our Construction.}
Following the blueprint of Mahadev's construction, our construction proceeds in the following two steps: 1. construct a $\QPIP_1$ protocol for $\SampBQP$ with required special property, and 2. compile the $\QPIP_1$ protocol using $\PiMeasure$ to get the desired $\QPIP_0$ protocol. The first step can be done by combining existing techniques from different contexts, whereas the second step is the main technical challenge.
At a high-level, the reason is the above-mentioned issue that the verifier does not learn the measurement outcome in the testing round. While this is not a problem for decision problems,
for sampling problems, the verifier needs to produce an output sample when accepts, but there seems to be no way to produce the output for the verifier without learning the measurement outcome.   
We discuss both steps in turn as follows.

\emph{$\diamond$ Construct a $\QPIP_1$ protocol for $\SampBQP$ with required special property}: Interestingly, while the notion of delegation for quantum sampling problem is not explicitly formalized in their work, Hayashi and Morimae~\cite{hayashi2015verifiable} constructed an one-round $\QPIP_1$ protocol that can delegate quantum sampling problem and achieve our notion of completeness and soundness\footnote{They did not prove our notion of soundness for their construction, but it is not hard to prove its soundness based on their analysis.}. Furthermore, their protocol has information-theoretic security and additionally achieve the blindness property. However, in their protocol, the computation is performed by the verifier using measurement-based quantum computation (MBQC)\footnote{In more detail, the prover of their protocol is required to send multiple copies of the graph states to the verifier (qubit by qubit). The verifier tests the received supposedly graph states using cut-and-choose and perform the computation using MBQC.}, and hence the verifier needs to perform adaptive measurement choices. Therefore, we cannot rely on their $\QPIP_1$ protocol for $\SampBQP$. 

Instead, we construct the desired $\QPIP_1$ protocol for $\SampBQP$ by generalizing the approach of local Hamiltonian reduction used in~\cite{PhysRevA.93.022326, mf16} to verify $\SampBQP$. Doing so requires the combination of several existing techniques from different context with some new ideas. For example, to handle $\SampBQP$, we need to prove lower bound on the spectral gap of the reduced local Hamiltonian instance, which is reminiscent to the simulation of quantum circuits by adiabatic quantum computation~\cite{adiabatic}. To achieve soundness, we use cut-and-choose and analyze it using de Finetti theorem in a  way similar to~\cite{takeuchi2018verification,hayashi2015verifiable}. See Section~\ref{sec:qpip1} for detailed discussions.



\emph{$\diamond$ Compile the $\QPIP_1$ protocol using $\PiMeasure$}: We now discuss how to use Mahadev's measurement protocol to compile the above $\QPIP_1$ protocol for $\SampBQP$ to a $\QPIP_0$ protocol. As mentioned, a major issue we need to address in Mahadev's original construction is that when the verifier $V$ chooses to run a testing round, $V$ does not learn an output sample when it accepts.  %(which happens with probability $1/2$), 

Specifically, let $\PiNaive$ be an ``intermediate'' $\QPIP_0$ protocol obtained by applying Mahadev's compilation to the above $\QPIP_1$ protocol. In such a protocol, when the verifier $V$ chooses to run the Hadamard round, it could learn a measurement outcome from the measurement protocol and be able to run the $\QPIP_1$ verifier to generate a decision and an output sample when accepts. However, when  $V$ chooses to run the testing round, it only decides to accept/reject without being able to output a sample. 

 A natural idea to fix the issue is to execute multiple copies of $\PiNaive$ in parallel\footnote{It is also reasonable to consider sequential repetition, but we consider parallel repetition for its advantage of preserving the round complexity.}, and to choose a random copy to run the Hadamard round to generate an output sample and use all the remaining copies to run the testing round. The verifier accepts only when all executions accept and outputs the sample from the Hadamard round. We call this protocol $\PiSampZ$.

Clearly from the construction, the verifier now can output a sample when it decides to accept, and output a correct sample when interacting with an honest prover (completeness). The challenge is to show that $\PiSampZ$ is computationally sound. Since we are now in the computational setting, we cannot use the quantum de Finetti theorem as above which only holds in the information-theoretical setting. Furthermore, parallel repetition for computationally sound protocols are typically difficult to analyze, and known to not always work for protocols with four or more messages even in the classical setting~\cite{BIN97,PW12}.


 Parallel repetition of Mahadev's protocol for $\BQP$ has been analyzed before in ~\cite{arXiv:ChiaChungYam19, arXiv:AlaChiHun19}. However, the situation here is different. 
 For $\BQP$, the verifier simply chooses to run the Hadamard and testing rounds independently for each repetition.
 In contrast, our $\PiSampZ$ runs the Hadamard round in one repetition and runs the testing rounds in the rest. The reason is that in $\SampBQP$, as well as generically in sampling problems, there is no known approach to combine multiple samples to generate one sample with reduced error, i.e., there is no generic error reduction method for the sampling problem. 
In contrast, the error reduction for decision problems can be done with the majority vote. 
As a result, while the soundness error decreases exponentially for $\BQP$, as we see below (and also in the above $\QPIP_1$ protocols), for $\SampBQP$, $m$-fold repetition only decreases the error to $\poly(1/m)$. 

To analyze the soundness of $\PiSampZ$, we use the \emph{partition lemma} developed in~\cite{arXiv:ChiaChungYam19} to analyze the prover's behavior while executing copies of $\PiMeasure$.\footnote{The analysis of \cite{arXiv:AlaChiHun19} is more tailored to the decision problems setting, and it is unclear how to extend it to sampling problems where there are multiple bits of output.} Intuitively, the partition lemma says that for any cheating prover and for each copy $i\in[m]$, there exist two efficient ``projectors" \footnote{Actually they are not projectors, but for the simplicity of this discussion let's assume they are.} $G_{0,i}$ and $G_{1,i}$ in the prover's internal space with $G_{0,i}+G_{1,i} \approx Id$. $G_{0,i}$ and $G_{1,i}$ splits up the prover's residual internal state after sending back his first message.
$G_{0,i}$ intuitively represents the subspace where the prover does not knows the answer to the testing round on the $i$-th copy, while $G_{1,i}$ represents the subspace where the prover does. Note that the prover is using a single internal space for all copies, and every $G_{0,i}$ and every $G_{1,i}$ is acting on this single internal space. 
By using this partition lemma iteratively, we can decompose the prover's internal state $\ket{\psi}$ into sum of subnormalized states.
First we apply it to the first copy, writing $\ket{\psi}=G_{0,1}\ket{\psi}+G_{1,1}\ket{\psi} \equiv \ket{\psi_0}+\ket{\psi_1}$.
The component $\ket{\psi_0}$ would then get rejected as long as the first copy is chosen as a testing round,
which occurs with pretty high probability.
More precisely, the output corresponding to $\ket{\psi_0}$ is $1/m$-close to the ideal distribution that just rejects all the time.
On the other hand, $\ket{\psi_1}$ is now binding on the first copy;
we now similarly apply the partition lemma of the second copy to $\ket{\psi_1}$.
We write $\ket{\psi_1}=G_{0,2}\ket{\psi_1}+G_{1,2}\ket{\psi_1}\equiv \ket{\psi_{10}}+\ket{\psi_{11}}$, and apply the same argument about $\ket{\psi_{10}}$ and $\ket{\psi_{11}}$.
We then continue to decompose $\ket{\psi_{11}}=\ket{\psi_{110}}+\ket{\psi_{111}}$ and so on, until we reach the last copy and obtain $\ket{\psi_{1^m}}$.
Intuitively, all the $\ket{\psi_{1\dots10}}$ terms will be rejected with high probability, while the $\ket{\psi_{1^m}}$ term represents the ``good" component where the prover knows the answer to every testing round and therefore has high accept probability. Therefore, $\ket{\psi_{1^m}}$ also satisfies some binding property,
so the verifier should obtain a measurement result of some state on the Hadamard round copy,
and the soundness of the $\QPIP_1$ protocol $\PiSamp$ follows.

However, the intuition that $\ket{\psi_{1^m}}$ is binding to every Hadamard round is incorrect. As $G_{1,i}$ does not commute with $G_{1,j}$, $\ket{\psi_{1^m}}$ is unfortunately only binding for the $m$-th copy.
To solve this problem, we start with a pointwise argument and fix the Hadamard round on the $i$-th copy where $\ket{\psi_{1^i}}$ is binding,
and show that the corresponding output is $O(\norm{\ket{\psi_{1^{i-1}0}}})$-close to ideal.
We can later average out this error over the different choices of $i$, since not all $\norm{\ket{\psi_{1^{i-1}0}}}$ can be large at the same time. Another way to see this issue is to notice that we are partitioning a quantum state, not probability events, so there are some inconsistencies between our intuition and calculation. Indeed, the error we get in the end is $O(\sqrt{1/m})$ instead of the $O(1/m)$ we expected. 

The intuitive analysis outlined above glosses over many technical details, and we substantiate this outline with full details in 
Section~\ref{sec:qpip0_all}.

\subsection{Blind CVQC Protocols} \label{subsection:blind}



Another desirable property of CVQC protocols is  \emph{blindness}, which means that the prover does not learn any information about the private input for the delegated computation.\footnote{In literature, the definition of blindness may also require to additionally hide the computation. We note the two notions are equivalent from a feasibility point of view by a standard transformation (see Remark~\ref{rmk:blind-comp} in Section~\ref{sec:qpip_def}). 
} In the relaxed setting where the verifier has a limited quantum capability, Hayashi and Morimae~\cite{hayashi2015verifiable} constructed a blind $\QPIP_1$ protocol for delegating quantum computation with information-theoretic security that also handles sampling problems. 
However, for purely classical verifiers, blind CVQC protocols seem much more difficult to construct. This goal is recently achieved by the seminal work of Gheorghiu and Vidick~\cite{FOCS:GheVid19}, who constructed the first blind CVQC protocol for $\BQP$ by constructing a composable remote state preparation protocol and combining it with the verifiable blind quantum computation protocol of Fitzsimons and Kashefi~\cite{FK17}. However, their protocol has   polynomially many rounds  and requires a rather involved analysis. Before our work, it is an open question whether constant-round blind CVQC protocol for $\BQP$ is achievable.

\paragraph{Our Contribution.} Somewhat surprisingly, we provide a simple yet powerful  
\emph{generic}  compiler that transforms any CVQC protocol to a blind one while preserving completeness, soundness, as well as its round complexity. 
Our compiler relies on quantum fully homomorphic encryption (QFHE) schemes with certain ``classical-friendly'' properties, which is satisfied by both constructions of Mahadev~\cite{mahadev_qfhe} and Brakerski~\cite{brakerski_qfhe}.

\begin{theorem}[informal]
Assuming the QLWE assumption\footnote{By using Brakerski's QFHE, we only need to rely on the QLWE assumption with polynomial modulus in this theorem.}, there exists a protocol compiler that transforms any CVQC protocol $\Pi$ to a CVQC protocol $\Piblind$ that achieves blindness while preserves its round complexity, completeness, and soundness.
\end{theorem}

Applying our blindness compiler to the parallel repetition of Mahadev's protocol from~\cite{arXiv:ChiaChungYam19, arXiv:AlaChiHun19}, we obtain the first constant-round blind CVQC protocol for $\BQP$ with negligible completeness and soundness error, resolving the aforementioned open question.

\begin{theorem}[informal]
    Under the QLWE assumption, there exists a blind, four-message CVQC protocol for all languages in $\BQP$ with negligible completeness and soundness errors.
\end{theorem}

We can also apply our compier to our CVQC protocol for $\SampBQP$ to additionally achieve blindness. 

\begin{theorem}[informal]
        Under the QLWE assumption, there exists a blind, four-message CVQC protocol for all sampling problems in $\SampBQP$ with  computational soundness and negligible completeness error.
\end{theorem}


\paragraph{Techniques.} At a high-level, the idea is simple: we run the original protocol under a QFHE with the QFHE key generated by the verifier. Intuitively, this allows the prover to compute his next message under encryption without learning verifier's message, and hence achieves blindness while preserving the properties of the original protocol.
One subtlety with this approach is the fact that the verifier is classical while the QFHE cipher text could contain quantum data.
In order to make the classical verifier work in this construction, the ciphertext and the encryption/decryption algorithm need to be classical when the underlying message is classical. Fortunately, such  ``classical-friendly'' property is satisfied by the construction of~\cite{mahadev_qfhe, brakerski_qfhe}.

A more subtle issue is to preserve the soundness.
In particular, compiled protocols with a single application of QFHE might (1) leak information about the circuit evaluated by the verifier through its outputted QFHE ciphertexts (i.e., no \emph{circuit privacy});
or (2) fail to simulate original protocols upon receiving invalid ciphertexts from the prover.
We address these issues by letting the verifier switch to a fresh new key for each round of the protocol. 
Details are given in \Cref{sec:BlindBQP2}.

\vspace{-3pt}

\subsection{Related and Followup Works and Discussions}  \label{subsec:discussion}

As mentioned, while we are the first to explicitly investigate delegation of quantum sampling problems, Hayashi and Morimae~\cite{hayashi2015verifiable} constructed an one-round blind $\QPIP_1$ protocol that can be used to delegate $\SampBQP$ and achieve our notion of information-theoretical security. Like our $\SampBQP$ protocol, their protocol has an arbitrarily small inverse polynomial soundness error instead of negligible soundness error. Also as mentioned,  Gheorghiu and Vidick~\cite{FOCS:GheVid19} constructed the first blind CVQC protocol for $\BQP$ by constructing a composable remote state preparation protocol and combining it with the verifiable blind quantum computation protocol of Fitzsimons and Kashefi~\cite{FK17}. However, their protocol has polynomially many rounds  and requires a rather involved analysis. 

It is also worth noting that several existing constructions in the relaxed models (e.g., verifiable blind computation~\cite{FK17}) can be generalized to delegate $\SampBQP$ in a natural way, but it seems challenging to analyze the soundness of the generalized protocol. Furthermore, it is unlikely that these generalized protocols can achieve negligible soundness error for $\SampBQP$. The reason is that in all these constructions, some form of cut and choose are used to achieve soundness.
For sampling problems, as mentioned, there seems to be no generic way to combine multiple samples for error reduction, so the verifier needs to choose one sample to output in the cut and choose. In this case, an adversarial prover may choose to cheat on a random copy in the cut and choose and succeed in cheating with an inverse polynomial probability. 

On the other hand, while the definition of $\SampBQP$ in~\cite{aaronson_2013, Boson} allows an inverse polynomial error, there seems to be no fundamental barriers to achieve negligible error. It is conceivable that negligible error can be achieved using quantum error correction. Negligible security error is also achievable in the related settings of secure multi-party quantum computation ~\cite{CGS02,DNS12} and verifiable quantum FHE~\cite{ADSS17} based on verifiable quantum secret sharing or quantum authentication codes\footnote{The security definitions are not comparable, but it seems plausible that the techniques can be used to achieve negligible soundness error for sampling problems.}. However, both primitives require computing and communicating quantum encodings and are not applicable in the context of CVQC and $\QPIP_1$. An intriguing open problem is whether it is possible to achieve negligible soundness error with classical communication while delegating a quantum sampling problem.

In a recent work, Bartusek~\cite{bartuseksecure} used the technique we developed for delegation of $\SampBQP$ to construct secure quantum computation protocols with classical communication for pseudo-deterministic quantum functionalities.

\paragraph{Organization}
We provide preliminaries on technical background in Section~\ref{sec:prelim}. 
Our simulation-based definition of CVQC for $\SampBQP$ is discussed in Section~\ref{sec:samp_definition}. 
Our main technical contributions are explained in Section~\ref{sec:sampbqp_short} (a construction of $\QPIP_1$ protocol for $\SampBQP$), 
Section~\ref{sec:qpip0_all} (the construction of $\QPIP_0$ protocol for $\SampBQP$ based on the above $\QPIP_1$ protocol), 
and Section~\ref{sec:BlindBQP2} (a generic compiler to upgrade $\QPIP_0$ protocols with blindness). 
